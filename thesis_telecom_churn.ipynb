{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dadakys/telecom-churn-prediction/blob/main/thesis_telecom_churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Obkca1oE7F8"
      },
      "outputs": [],
      "source": [
        "#import necessary libraries\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxHsNTScFBGs"
      },
      "outputs": [],
      "source": [
        "#import dataset from google drive\n",
        "drive.mount('/content/drive')\n",
        "file_path='/content/drive/My Drive/SXOLH2/thesis/cell2celltrain.csv'\n",
        "df=pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA8LgQvbyXkZ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Basic info for the dataset\n",
        "print(df.shape)\n",
        "print(df.columns)\n",
        "print(df.dtypes)\n",
        "print(df.head())\n",
        "print(df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpz9jf_4YJVN",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#VISUALIZATIONS\n",
        "# Churn distribution with value labels\n",
        "plt.figure(figsize=(6, 5))\n",
        "ax = sns.countplot(data=df, x='Churn')\n",
        "plt.title('Churn Distribution')\n",
        "plt.xlabel('Churned')\n",
        "plt.ylabel('Customers')\n",
        "\n",
        "# Add count labels on top of each bar\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.text(p.get_x() + p.get_width() / 2., height + 500, int(height), ha=\"center\", fontsize=12)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tos49MO6aVxC"
      },
      "outputs": [],
      "source": [
        "#VISUALIZE BOXPLOTS\n",
        "\n",
        "# Make sure Churn is treated as a category\n",
        "df['Churn'] = df['Churn'].astype(str)\n",
        "\n",
        "# Select numeric columns (exclude ID/encoded target if necessary)\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.drop(['CustomerID'])\n",
        "\n",
        "# Create a boxplot for each numeric column grouped by Churn\n",
        "for col in numeric_cols:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.boxplot(data=df, x='Churn', y=col)\n",
        "    plt.title(f'Boxplot of {col} ')\n",
        "    plt.xlabel('Churn')\n",
        "    plt.ylabel(col)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "48c9vhBNcIo4"
      },
      "outputs": [],
      "source": [
        "#VISUALIZE HISTOGRAMS\n",
        "\n",
        "# Select numeric features (excluding CustomerID and target)\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.drop(['CustomerID'])\n",
        "\n",
        "# Loop through and create histograms for each feature by class\n",
        "for col in numeric_cols:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "\n",
        "    # Plot histogram for each class\n",
        "    for label in df['Churn'].unique():\n",
        "        subset = df[df['Churn'] == label]\n",
        "        plt.hist(subset[col], bins=30, alpha=0.6, label=f'Churn = {label}', density=True,edgecolor='black')\n",
        "\n",
        "    plt.title(f'Histogram of {col} by Churn')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CrZe9lyYZOVx"
      },
      "outputs": [],
      "source": [
        "# DATA PREPARATION / PREPROCESSING\n",
        "\n",
        "# 1. Duplicate check\n",
        "duplicate_rows = df.duplicated()\n",
        "num_duplicates = duplicate_rows.sum()\n",
        "print(f\"Number of duplicate rows: {num_duplicates}\")\n",
        "\n",
        "# 2. Missing value check (now includes percentage)\n",
        "missing_count = df.isnull().sum()\n",
        "missing_percent = (missing_count / len(df)) * 100\n",
        "\n",
        "# Filter only columns with missing values\n",
        "missing_data = pd.DataFrame({\n",
        "    'Missing Values': missing_count[missing_count > 0],\n",
        "    'Percent Missing (%)': missing_percent[missing_count > 0].round(2)\n",
        "})\n",
        "\n",
        "if not missing_data.empty:\n",
        "    print(\"There are missing values in the dataset.\")\n",
        "    print(\"Here is the count and percentage of missing values for each column:\\n\")\n",
        "    print(missing_data)\n",
        "\n",
        "    # Columns to fill\n",
        "    num_cols_to_fill = [\n",
        "        'MonthlyRevenue', 'MonthlyMinutes', 'TotalRecurringCharge',\n",
        "        'DirectorAssistedCalls', 'OverageMinutes', 'RoamingCalls',\n",
        "        'PercChangeMinutes', 'PercChangeRevenues',\n",
        "        'Handsets', 'HandsetModels', 'CurrentEquipmentDays',\n",
        "        'AgeHH1', 'AgeHH2'\n",
        "    ]\n",
        "    cat_cols_to_fill = ['ServiceArea']\n",
        "\n",
        "    # Fill numerical columns with median\n",
        "    for col in num_cols_to_fill:\n",
        "        median_val = df[col].median()\n",
        "        df[col] = df[col].fillna(median_val)\n",
        "        print(f\"Filled missing values in '{col}' with median: {median_val}\")\n",
        "\n",
        "    # Fill categorical column with mode\n",
        "    for col in cat_cols_to_fill:\n",
        "        mode_val = df[col].mode()[0]\n",
        "        df[col] = df[col].fillna(mode_val)\n",
        "        print(f\"Filled missing values in '{col}' with mode: {mode_val}\")\n",
        "\n",
        "    print(\"\\n‚úÖ Missing values handled.\")\n",
        "else:\n",
        "    print(\"No missing values found in the dataset.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mZ2gRkjPeuG8"
      },
      "outputs": [],
      "source": [
        "# Check for outliers\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.drop(['CustomerID'])\n",
        "\n",
        "print(\"üîç Outlier Clipping Report:\\n\")\n",
        "outlier_summary = []\n",
        "for col in numeric_cols:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 3 * IQR\n",
        "    upper_bound = Q3 + 3 * IQR\n",
        "\n",
        "    # Count outliers BEFORE clipping\n",
        "    outliers_before = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
        "\n",
        "    if outliers_before > 0:\n",
        "        min_before, max_before = df[col].min(), df[col].max()\n",
        "\n",
        "        # Clip the values\n",
        "        df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
        "        min_after, max_after = df[col].min(), df[col].max()\n",
        "        outlier_summary.append({\n",
        "            \"Feature Name\": col,\n",
        "            \"Outliers Clipped\": outliers_before\n",
        "        })\n",
        "        print(f\"üßæ {col}:\")\n",
        "        print(f\"   Outliers clipped: {outliers_before}\")\n",
        "        print(f\"   Min/Max before: {min_before} / {max_before}\")\n",
        "        print(f\"   Min/Max after:  {min_after} / {max_after}\\n\")\n",
        "outlier_df=pd.DataFrame(outlier_summary)\n",
        "outlier_df.to_csv(\"outliers.csv\",index=False)\n",
        "print(\"‚úÖ Outliers handled.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot7IfYB841cB"
      },
      "outputs": [],
      "source": [
        "#FEATURE SELECTION\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# Remove features with near-zero variance\n",
        "selector = VarianceThreshold(threshold=0.01)\n",
        "selector.fit(df.select_dtypes(include=['number']))  # only numeric columns\n",
        "\n",
        "low_variance_cols = df.select_dtypes(include=['number']).columns[~selector.get_support()]\n",
        "print(\"Low-variance features to consider removing:\", list(low_variance_cols))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SQkTYlwlPXU"
      },
      "outputs": [],
      "source": [
        "# Drop features with extremely low variance or clipped entirely to 0 after outlier handling\n",
        "columns_to_drop = [\n",
        "    'RetentionCalls',\n",
        "    'RetentionOffersAccepted',\n",
        "    'ReferralsMadeBySubscriber',\n",
        "    'CallForwardingCalls',\n",
        "    'AdjustmentsToCreditRating'\n",
        "]\n",
        "df.drop(columns=columns_to_drop, inplace=True)\n",
        "print(\"Dropped columns:\", columns_to_drop)\n",
        "# Dropping features due to extremely low variance or being fully clipped to 0 during outlier treatment.\n",
        "# These features provide minimal signal for modeling and could introduce noise or unnecessary complexity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ST0M2EGuA6lf"
      },
      "outputs": [],
      "source": [
        "# Compute correlation matrix\n",
        "corr_matrix = df.select_dtypes(include=['number']).corr().abs()\n",
        "\n",
        "# Upper triangle of correlation matrix\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "# Find features with correlation > 0.8\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
        "\n",
        "print(\"Highly correlated features to consider dropping:\", to_drop)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ests_m43BeQK"
      },
      "outputs": [],
      "source": [
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "  # Prepare data\n",
        "  X = df.drop(columns=['Churn', 'CustomerID'])  # exclude target and ID\n",
        "  y = df['Churn'].map({'Yes': 1, 'No': 0})       # encode target\n",
        "\n",
        "  # Handle categorical features (basic encoding)\n",
        "  X_encoded = pd.get_dummies(X)\n",
        "\n",
        "  # Fit random forest\n",
        "  model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "  model.fit(X_encoded, y)\n",
        "\n",
        "  # Feature importances\n",
        "  importances = pd.Series(model.feature_importances_, index=X_encoded.columns)\n",
        "  important_features = importances.sort_values(ascending=False)\n",
        "  top_20_features = important_features.head(20).index.tolist()\n",
        "  # Plot top 20 features\n",
        "  important_features.head(20).plot(kind='barh', figsize=(10, 8), title='Top 20 Important Features')\n",
        "  plt.gca().invert_yaxis()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOkq1F4zZ3jn"
      },
      "outputs": [],
      "source": [
        "#check correlation for potential drop\n",
        "print(df[['DroppedCalls', 'BlockedCalls', 'DroppedBlockedCalls']].corr())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEucV8GofTL4"
      },
      "outputs": [],
      "source": [
        "# Dropping 'DroppedBlockedCalls' as it is a derived feature (sum of DroppedCalls and BlockedCalls)\n",
        "# and is highly correlated with both. Also dropping 'ActiveSubs' and 'HandsetModels' due to high correlation\n",
        "# and low importance in feature ranking.\n",
        "df.drop(columns=['DroppedBlockedCalls', 'ActiveSubs', 'HandsetModels'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPSQf8VjfVAB"
      },
      "outputs": [],
      "source": [
        "#check the dataset to see if the features dropped\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "y1ZEAf7A0QdQ"
      },
      "outputs": [],
      "source": [
        "#check unique values (categories) for each column before encoding\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        print(f\"\\nColumn: {col}\")\n",
        "        print(df[col].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  One-plot summary: ‚ÄúUnknown‚Äù vs numeric values in HandsetPrice\n",
        "import os\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/plots\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "# ‚îÄ‚îÄ detect rows that were literal \"Unknown\" before conversion ‚îÄ‚îÄ\n",
        "mask_unknown = df[\"HandsetPrice\"].astype(str).str.lower() == \"unknown\"\n",
        "df[\"HandsetPriceStatus\"] = pd.Series(\n",
        "    np.where(mask_unknown, \"Unknown\", \"Numeric\"), index=df.index)\n",
        "\n",
        "counts = df[\"HandsetPriceStatus\"].value_counts().reindex([\"Numeric\", \"Unknown\"])\n",
        "\n",
        "# ‚îÄ‚îÄ plot & save ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.barplot(x=counts.index, y=counts.values, palette=\"Blues\")\n",
        "plt.title(\"HandsetPrice Distribution\")\n",
        "plt.ylabel(\"Count\"); plt.xlabel(\"\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(out_dir, \"handset_unknown_vs_numeric.png\"), dpi=300)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "lZyClP9wgp6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "t8yr-xg0CvFl"
      },
      "outputs": [],
      "source": [
        "#  Final Preprocessing Cell\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Group rare ServiceAreas\n",
        "area_counts = df['ServiceArea'].value_counts()\n",
        "top_areas = area_counts[area_counts > 100].index\n",
        "df['ServiceArea'] = df['ServiceArea'].where(df['ServiceArea'].isin(top_areas), other='Other')\n",
        "\n",
        "# 2. Encode target\n",
        "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# 3. Encode binary \"Yes\"/\"No\" features\n",
        "binary_cols = [\n",
        "    'HandsetRefurbished', 'HandsetWebCapable', 'TruckOwner', 'RVOwner',\n",
        "    'BuysViaMailOrder', 'RespondsToMailOffers',\n",
        "    'OptOutMailings', 'NonUSTravel', 'OwnsComputer', 'HasCreditCard',\n",
        "    'NewCellphoneUser', 'NotNewCellphoneUser', 'OwnsMotorcycle',\n",
        "    'ChildrenInHH', 'MadeCallToRetentionTeam'\n",
        "]\n",
        "for col in binary_cols:\n",
        "    df[col] = df[col].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# 4. Encode 'Homeownership' and 'MaritalStatus'\n",
        "df['Homeownership'] = df['Homeownership'].map({'Known': 1, 'Unknown': 0})\n",
        "df['MaritalStatus'] = df['MaritalStatus'].map({'Yes': 1, 'No': 0, 'Unknown': 2})\n",
        "\n",
        "# 5. Handle 'HandsetPrice' (convert and fill missing)\n",
        "df['HandsetPrice'] = pd.to_numeric(df['HandsetPrice'], errors='coerce')\n",
        "df['HandsetPrice'].fillna(df['HandsetPrice'].median(), inplace=True)\n",
        "\n",
        "# 6. Ordinal encode 'CreditRating'\n",
        "credit_rating_map = {\n",
        "    '1-Highest': 1,\n",
        "    '2-High': 2,\n",
        "    '3-Good': 3,\n",
        "    '4-Medium': 4,\n",
        "    '5-Low': 5,\n",
        "    '6-Very Low': 6,\n",
        "    '7-Lowest': 7\n",
        "}\n",
        "df['CreditRating'] = df['CreditRating'].map(credit_rating_map)\n",
        "df['CreditRating'].fillna(df['CreditRating'].median(), inplace=True)\n",
        "\n",
        "# 7. Encode ServiceArea (after grouping)\n",
        "service_area_mapping = {area: idx for idx, area in enumerate(sorted(df['ServiceArea'].unique()))}\n",
        "df['ServiceArea'] = df['ServiceArea'].map(service_area_mapping)\n",
        "\n",
        "# 8. Encode PrizmCode\n",
        "prizm_code_map = {\n",
        "    'Suburban': 0,\n",
        "    'Town': 1,\n",
        "    'Other': 2,\n",
        "    'Rural': 3\n",
        "}\n",
        "df['PrizmCode'] = df['PrizmCode'].map(prizm_code_map)\n",
        "\n",
        "# 9. Encode Occupation\n",
        "occupation_map = {\n",
        "    'Professional': 0,\n",
        "    'Crafts': 1,\n",
        "    'Other': 2,\n",
        "    'Self': 3,\n",
        "    'Retired': 4,\n",
        "    'Homemaker': 5,\n",
        "    'Clerical': 6,\n",
        "    'Student': 7\n",
        "}\n",
        "df['Occupation'] = df['Occupation'].map(occupation_map)\n",
        "\n",
        "# 10. Separate features and target\n",
        "X = df.drop(columns=['Churn', 'CustomerID'])\n",
        "y = df['Churn']\n",
        "\n",
        "# 11. Scale numeric features\n",
        "scaler = StandardScaler()\n",
        "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
        "\n",
        "# 12. Final check\n",
        "print(\"\\n‚úÖ Final Check:\")\n",
        "print(f\"Remaining missing values: {X.isnull().sum().sum()}\")\n",
        "print(f\"All columns numeric: {all(dtype in ['int64', 'float64'] for dtype in X.dtypes)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkwpUWHcpjKN"
      },
      "outputs": [],
      "source": [
        "#Check for remaining columns that need encoding\n",
        "non_numeric_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "print(\"Columns that still need encoding:\", list(non_numeric_cols))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save features barplots/histograms\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/plots\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# ‚îÄ‚îÄ inverse look-ups ----------------------------------------------------------\n",
        "prizm_inv = {0: \"Suburban\", 1: \"Town\", 2: \"Other\", 3: \"Rural\"}\n",
        "occupation_inv = {\n",
        "    0: \"Professional\", 1: \"Crafts\", 2: \"Other\", 3: \"Self\",\n",
        "    4: \"Retired\", 5: \"Homemaker\", 6: \"Clerical\", 7: \"Student\"\n",
        "}\n",
        "marital_inv = {1: \"Yes\", 0: \"No\", 2: \"Unknown\"}\n",
        "credit_inv = {\n",
        "    1: \"1-Highest\", 2: \"2-High\", 3: \"3-Good\", 4: \"4-Medium\",\n",
        "    5: \"5-Low\", 6: \"6-Very Low\", 7: \"7-Lowest\"\n",
        "}\n",
        "\n",
        "# ‚îÄ‚îÄ helper to save bar plots --------------------------------------------------\n",
        "def barplot_and_save(counts: pd.Series, title: str, filename: str, rot=0):\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.barplot(x=counts.index, y=counts.values)\n",
        "    plt.title(title)\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.xlabel(\"\")          # leave x-label blank; title says enough\n",
        "    plt.xticks(rotation=rot)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(out_dir, filename), dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "# 1. HandsetPrice histogram ----------------------------------------------------\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(df[\"HandsetPrice\"], bins=30, kde=True)\n",
        "plt.title(\"HandsetPrice Distribution\")\n",
        "plt.xlabel(\"HandsetPrice\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(out_dir, \"handsetprice_dist.png\"), dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# 2. PrizmCode barplot ---------------------------------------------------------\n",
        "prizm_counts = df[\"PrizmCode\"].map(prizm_inv).value_counts().sort_index()\n",
        "barplot_and_save(prizm_counts, \"PrizmCode Distribution\", \"prizmcode_dist.png\")\n",
        "\n",
        "# 3. Occupation barplot --------------------------------------------------------\n",
        "occ_counts = df[\"Occupation\"].map(occupation_inv).value_counts().sort_index()\n",
        "barplot_and_save(occ_counts, \"Occupation Distribution\", \"occupation_dist.png\", rot=35)\n",
        "\n",
        "# 4. MaritalStatus barplot -----------------------------------------------------\n",
        "mar_counts = df[\"MaritalStatus\"].map(marital_inv).value_counts().sort_index()\n",
        "barplot_and_save(mar_counts, \"Marital Status Distribution\", \"maritalstatus_dist.png\")\n",
        "\n",
        "# 5. CreditRating barplot ------------------------------------------------------\n",
        "cred_counts = df[\"CreditRating\"].map(credit_inv).value_counts().sort_index()\n",
        "barplot_and_save(cred_counts, \"Credit Rating Distribution\", \"creditrating_dist.png\")\n",
        "\n",
        "print(f\"üéâ  Saved five separate PNG files to {out_dir}\")\n"
      ],
      "metadata": {
        "id": "Id0b6hIkk-a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution plots for key variables (HandsetPrice, PrizmCode, Occupation,\n",
        "#    MaritalStatus, CreditRating)\n",
        "\n",
        "\n",
        "# ‚îÄ‚îÄ inverse look-ups to restore human-readable category names ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "prizm_inv = {0: \"Suburban\", 1: \"Town\", 2: \"Other\", 3: \"Rural\"}\n",
        "occupation_inv = {\n",
        "    0: \"Professional\", 1: \"Crafts\", 2: \"Other\", 3: \"Self\",\n",
        "    4: \"Retired\", 5: \"Homemaker\", 6: \"Clerical\", 7: \"Student\"\n",
        "}\n",
        "marital_inv = {1: \"Yes\", 0: \"No\", 2: \"Unknown\"}\n",
        "credit_inv = {\n",
        "    1: \"1-Highest\", 2: \"2-High\", 3: \"3-Good\", 4: \"4-Medium\",\n",
        "    5: \"5-Low\", 6: \"6-Very Low\", 7: \"7-Lowest\"\n",
        "}\n",
        "\n",
        "# ‚îÄ‚îÄ value counts for categorical columns ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "prizm_counts      = df[\"PrizmCode\"].map(prizm_inv).value_counts().sort_index()\n",
        "occupation_counts = df[\"Occupation\"].map(occupation_inv).value_counts().sort_index()\n",
        "marital_counts    = df[\"MaritalStatus\"].map(marital_inv).value_counts().sort_index()\n",
        "credit_counts     = df[\"CreditRating\"].map(credit_inv).value_counts().sort_index()\n",
        "\n",
        "# ‚îÄ‚îÄ create a 3 √ó 2 subplot grid (5 plots, last cell empty) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "fig, axes = plt.subplots(3, 2, figsize=(15, 14))\n",
        "axes = axes.flatten()              # easier indexing (total 6 axes)\n",
        "\n",
        "# 1. HandsetPrice (numeric histogram)\n",
        "sns.histplot(df[\"HandsetPrice\"], bins=30, kde=True, ax=axes[0])\n",
        "axes[0].set_title(\"HandsetPrice Distribution\")\n",
        "axes[0].set_xlabel(\"HandsetPrice\")\n",
        "\n",
        "# 2. PrizmCode\n",
        "sns.barplot(x=prizm_counts.index, y=prizm_counts.values, ax=axes[1])\n",
        "axes[1].set_title(\"PrizmCode Distribution\")\n",
        "axes[1].set_xlabel(\"PrizmCode\")\n",
        "axes[1].set_ylabel(\"Count\")\n",
        "\n",
        "# 3. Occupation\n",
        "sns.barplot(x=occupation_counts.index, y=occupation_counts.values, ax=axes[2])\n",
        "axes[2].set_title(\"Occupation Distribution\")\n",
        "axes[2].set_xlabel(\"Occupation\")\n",
        "axes[2].set_ylabel(\"Count\")\n",
        "axes[2].tick_params(axis=\"x\", rotation=35)\n",
        "\n",
        "# 4. MaritalStatus\n",
        "sns.barplot(x=marital_counts.index, y=marital_counts.values, ax=axes[3])\n",
        "axes[3].set_title(\"Marital Status Distribution\")\n",
        "axes[3].set_xlabel(\"Marital Status\")\n",
        "axes[3].set_ylabel(\"Count\")\n",
        "\n",
        "# 5. CreditRating\n",
        "sns.barplot(x=credit_counts.index, y=credit_counts.values, ax=axes[4])\n",
        "axes[4].set_title(\"Credit Rating Distribution\")\n",
        "axes[4].set_xlabel(\"Credit Rating\")\n",
        "axes[4].set_ylabel(\"Count\")\n",
        "\n",
        "# Hide unused 6th subplot (axes[5])\n",
        "axes[5].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "UAp6gm9Ecw05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3i70QNndrPU"
      },
      "outputs": [],
      "source": [
        "# Split dataset with Stratified k fold\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# X and y are already prepared from your preprocessing\n",
        "# (X = features, y = churn target)\n",
        "\n",
        "# Initialize StratifiedKFold with 4 splits\n",
        "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "\n",
        "# Loop through the folds\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Get counts and percentages for training set\n",
        "    train_counts = y_train.value_counts()\n",
        "    train_percentages = y_train.value_counts(normalize=True) * 100\n",
        "\n",
        "    # Get counts and percentages for testing set\n",
        "    test_counts = y_test.value_counts()\n",
        "    test_percentages = y_test.value_counts(normalize=True) * 100\n",
        "\n",
        "    print(f\"Fold {fold + 1}:\")\n",
        "    print(\"Training set:\")\n",
        "    print(f\"  Not Churned (0): {train_counts[0]} ({train_percentages[0]:.2f}%)\")\n",
        "    print(f\"  Churned (1): {train_counts[1]} ({train_percentages[1]:.2f}%)\")\n",
        "    print(\"Testing set:\")\n",
        "    print(f\"  Not Churned (0): {test_counts[0]} ({test_percentages[0]:.2f}%)\")\n",
        "    print(f\"  Churned (1): {test_counts[1]} ({test_percentages[1]:.2f}%)\")\n",
        "    print(\"-\" * 40)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot class distribution across folds (train/test)\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Create list to store results\n",
        "fold_distributions = []\n",
        "\n",
        "# Initialize StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "\n",
        "# Loop through the folds\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n",
        "    y_train = y.iloc[train_idx]\n",
        "    y_test = y.iloc[test_idx]\n",
        "\n",
        "    train_dist = y_train.value_counts(normalize=True) * 100\n",
        "    test_dist = y_test.value_counts(normalize=True) * 100\n",
        "\n",
        "    fold_distributions.append({\n",
        "        'Fold': fold,\n",
        "        'Set': 'Train',\n",
        "        'Churned (%)': train_dist[1],\n",
        "        'Not Churned (%)': train_dist[0]\n",
        "    })\n",
        "    fold_distributions.append({\n",
        "        'Fold': fold,\n",
        "        'Set': 'Test',\n",
        "        'Churned (%)': test_dist[1],\n",
        "        'Not Churned (%)': test_dist[0]\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "dist_df = pd.DataFrame(fold_distributions)\n",
        "\n",
        "# Melt for seaborn visualization\n",
        "df_melted = dist_df.melt(id_vars=['Fold', 'Set'],\n",
        "                         value_vars=['Churned (%)', 'Not Churned (%)'],\n",
        "                         var_name='Class', value_name='Percentage')\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=df_melted, x='Fold', y='Percentage', hue='Class', ci=None, palette='Set2')\n",
        "plt.title('Class Distribution in Train/Test Sets Across Folds')\n",
        "plt.ylabel('Percentage (%)')\n",
        "plt.xlabel('Fold Number')\n",
        "plt.legend(title='Class Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VS9tUZP8Edhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PXGrtF0C4v-",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Experiment 1: Baseline (Default)\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Initialize logs\n",
        "results_df = pd.DataFrame(columns=[\n",
        "    \"Classifier Name\", \"Fold\", \"TrainOrTest\",\n",
        "    \"Num Train Samples\", \"Num Churned in Train\",\n",
        "    \"TP\", \"TN\", \"FP\", \"FN\", \"ROC-AUC\"\n",
        "])\n",
        "\n",
        "fold_metrics = {\n",
        "    \"Classifier\": [], \"Fold\": [],\n",
        "    \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 Score\": [], \"AUC ROC\": []\n",
        "}\n",
        "\n",
        "def log_metrics_to_df(df, classifier_name, fold_number, dataset_type, y_true, y_pred, X_data, y_data, y_prob):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "    roc_auc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
        "    row = {\n",
        "        \"Classifier Name\": classifier_name,\n",
        "        \"Fold\": fold_number,\n",
        "        \"TrainOrTest\": dataset_type,\n",
        "        \"Num Train Samples\": len(X_data),\n",
        "        \"Num Churned in Train\": sum(y_data == 1),\n",
        "        \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
        "        \"ROC-AUC\": roc_auc\n",
        "    }\n",
        "    return pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "\n",
        "# Classifier list\n",
        "classifiers_and_params = {\n",
        "    \"kNN\": (\n",
        "        KNeighborsClassifier(),\n",
        "        {\n",
        "            \"n_neighbors\": randint(1, 50),\n",
        "            \"weights\": [\"uniform\", \"distance\"],\n",
        "            \"p\": [1, 2]\n",
        "        }\n",
        "    ),\n",
        "    \"LDA\": (\n",
        "        LinearDiscriminantAnalysis(),\n",
        "        [\n",
        "            {\"solver\": [\"svd\"], \"shrinkage\": [None], \"tol\": uniform(1e-5, 1e-2)},\n",
        "            {\"solver\": [\"lsqr\", \"eigen\"], \"shrinkage\": [None, \"auto\"], \"tol\": uniform(1e-5, 1e-2)}\n",
        "        ]\n",
        "    ),\n",
        "    \"LogReg\": (\n",
        "        LogisticRegression(random_state=42, max_iter=1000),\n",
        "        {\n",
        "            \"C\": uniform(0.01, 10),\n",
        "            \"penalty\": [\"l1\", \"l2\"],\n",
        "            \"solver\": [\"liblinear\", \"saga\"]\n",
        "        }\n",
        "    ),\n",
        "    \"DecisionTree\": (\n",
        "        DecisionTreeClassifier(random_state=42),\n",
        "        {\n",
        "            \"max_depth\": randint(1, 20),\n",
        "            \"min_samples_split\": randint(2, 10),\n",
        "            \"min_samples_leaf\": randint(1, 10),\n",
        "            \"criterion\": [\"gini\", \"entropy\"]\n",
        "        }\n",
        "    ),\n",
        "    \"RandomForest\": (\n",
        "        RandomForestClassifier(random_state=42),\n",
        "        {\n",
        "            \"n_estimators\": randint(50, 300),\n",
        "            \"max_depth\": randint(1, 20),\n",
        "            \"min_samples_split\": randint(2, 10),\n",
        "            \"min_samples_leaf\": randint(1, 10),\n",
        "            \"criterion\": [\"gini\", \"entropy\"]\n",
        "        }\n",
        "    ),\n",
        "    \"NaiveBayes\": (\n",
        "        GaussianNB(),\n",
        "        {\n",
        "            \"var_smoothing\": uniform(1e-9, 1e-5)\n",
        "        }\n",
        "    ),\n",
        "    \"AdaBoost\": (\n",
        "        AdaBoostClassifier(random_state=42),\n",
        "        {\n",
        "            \"n_estimators\": randint(50, 300),\n",
        "            \"learning_rate\": uniform(0.01, 0.5)\n",
        "        }\n",
        "    )\n",
        "}\n",
        "\n",
        "# Begin loop\n",
        "fold_number = 1\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train_fold = X.iloc[train_index]\n",
        "    X_test_fold = X.iloc[test_index]\n",
        "    y_train_fold = y.iloc[train_index]\n",
        "    y_test_fold = y.iloc[test_index]\n",
        "\n",
        "    for clf_name, (clf_base, param_dist) in classifiers_and_params.items():\n",
        "        print(f\"\\nüîç {clf_name} on Fold {fold_number}\")\n",
        "\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=clf_base,\n",
        "            param_distributions=param_dist,\n",
        "            n_iter=10,\n",
        "            scoring=\"f1\",\n",
        "            cv=3,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        random_search.fit(X_train_fold, y_train_fold)\n",
        "        best_model = random_search.best_estimator_\n",
        "        print(\"Best params:\", random_search.best_params_)\n",
        "\n",
        "        y_train_pred = best_model.predict(X_train_fold)\n",
        "        y_test_pred = best_model.predict(X_test_fold)\n",
        "\n",
        "        y_train_prob = best_model.predict_proba(X_train_fold)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
        "        y_test_prob = best_model.predict_proba(X_test_fold)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
        "\n",
        "        # Evaluation\n",
        "        test_metrics = {\n",
        "            \"acc\": accuracy_score(y_test_fold, y_test_pred),\n",
        "            \"prec\": precision_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"rec\": recall_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"f1\": f1_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"auc\": roc_auc_score(y_test_fold, y_test_prob) if y_test_prob is not None else 0.0\n",
        "        }\n",
        "\n",
        "        print(f\"‚Üí Accuracy: {test_metrics['acc']:.3f} | F1: {test_metrics['f1']:.3f} | AUC: {test_metrics['auc']:.3f}\")\n",
        "\n",
        "        # Confusion Matrices\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        sns.heatmap(confusion_matrix(y_train_fold, y_train_pred), annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
        "        ax[0].set_title(f'{clf_name} - Fold {fold_number} - Train')\n",
        "\n",
        "        sns.heatmap(confusion_matrix(y_test_fold, y_test_pred), annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
        "        ax[1].set_title(f'{clf_name} - Fold {fold_number} - Test')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # ROC Curve\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        if y_train_prob is not None:\n",
        "            RocCurveDisplay.from_estimator(best_model, X_train_fold, y_train_fold, ax=ax[0])\n",
        "            ax[0].set_title(f\"{clf_name} - ROC (Train) - Fold {fold_number}\")\n",
        "        if y_test_prob is not None:\n",
        "            RocCurveDisplay.from_estimator(best_model, X_test_fold, y_test_fold, ax=ax[1])\n",
        "            ax[1].set_title(f\"{clf_name} - ROC (Test) - Fold {fold_number}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Save metrics\n",
        "        fold_metrics[\"Classifier\"].append(clf_name)\n",
        "        fold_metrics[\"Fold\"].append(fold_number)\n",
        "        fold_metrics[\"Accuracy\"].append(test_metrics[\"acc\"])\n",
        "        fold_metrics[\"Precision\"].append(test_metrics[\"prec\"])\n",
        "        fold_metrics[\"Recall\"].append(test_metrics[\"rec\"])\n",
        "        fold_metrics[\"F1 Score\"].append(test_metrics[\"f1\"])\n",
        "        fold_metrics[\"AUC ROC\"].append(test_metrics[\"auc\"])\n",
        "\n",
        "        # Detailed logs\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Train\", y_train_fold, y_train_pred, X_train_fold, y_train_fold, y_train_prob)\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Test\", y_test_fold, y_test_pred, X_test_fold, y_test_fold, y_test_prob)\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "# Summary\n",
        "print(\"\\nüìä Final Summary by Classifier (Average Across Folds):\")\n",
        "summary_df = pd.DataFrame(fold_metrics)\n",
        "grouped = summary_df.groupby(\"Classifier\")\n",
        "print(grouped.mean(numeric_only=True).round(3))\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv(\"churn_classifiers_output.csv\", index=False)\n",
        "print(\"\\n‚úÖ All results saved to churn_classifiers_output.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1: Adding 2 classifiers (boosters)\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "\n",
        "\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Initialize logs\n",
        "results_df = pd.DataFrame(columns=[\n",
        "    \"Classifier Name\", \"Fold\", \"TrainOrTest\",\n",
        "    \"Num Train Samples\", \"Num Churned in Train\",\n",
        "    \"TP\", \"TN\", \"FP\", \"FN\", \"ROC-AUC\"\n",
        "])\n",
        "\n",
        "fold_metrics = {\n",
        "    \"Classifier\": [], \"Fold\": [],\n",
        "    \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 Score\": [], \"AUC ROC\": []\n",
        "}\n",
        "\n",
        "def log_metrics_to_df(df, classifier_name, fold_number, dataset_type, y_true, y_pred, X_data, y_data, y_prob):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "    roc_auc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
        "    row = {\n",
        "        \"Classifier Name\": classifier_name,\n",
        "        \"Fold\": fold_number,\n",
        "        \"TrainOrTest\": dataset_type,\n",
        "        \"Num Train Samples\": len(X_data),\n",
        "        \"Num Churned in Train\": sum(y_data == 1),\n",
        "        \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
        "        \"ROC-AUC\": roc_auc\n",
        "    }\n",
        "    return pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "\n",
        "extra_classifiers = {\n",
        "    \"XGBoost\": (\n",
        "        XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1),\n",
        "        {\n",
        "            \"n_estimators\": randint(50, 300),\n",
        "            \"max_depth\": randint(3, 10),\n",
        "            \"learning_rate\": uniform(0.01, 0.3),\n",
        "            \"subsample\": uniform(0.6, 0.4),\n",
        "            \"colsample_bytree\": uniform(0.6, 0.4),\n",
        "            \"reg_alpha\": uniform(0, 1),\n",
        "            \"reg_lambda\": uniform(1, 3)\n",
        "        }\n",
        "    ),\n",
        "    \"GradientBoosting\": (\n",
        "        GradientBoostingClassifier(random_state=42),\n",
        "        {\n",
        "            \"n_estimators\": randint(50, 300),\n",
        "            \"max_depth\": randint(3, 10),\n",
        "            \"learning_rate\": uniform(0.01, 0.3),\n",
        "            \"subsample\": uniform(0.6, 0.4)\n",
        "        }\n",
        "    )\n",
        "}\n",
        "fold_number = 1\n",
        "# New experiments loop\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train_fold = X.iloc[train_index]\n",
        "    X_test_fold = X.iloc[test_index]\n",
        "    y_train_fold = y.iloc[train_index]\n",
        "    y_test_fold = y.iloc[test_index]\n",
        "\n",
        "    for clf_name, (clf_base, param_dist) in extra_classifiers.items():\n",
        "        print(f\"\\nüîç {clf_name} on Fold {fold_number}\")\n",
        "\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=clf_base,\n",
        "            param_distributions=param_dist,\n",
        "            n_iter=10,\n",
        "            scoring=\"f1\",\n",
        "            cv=3,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        random_search.fit(X_train_fold, y_train_fold)\n",
        "        best_model = random_search.best_estimator_\n",
        "        print(\"Best params:\", random_search.best_params_)\n",
        "\n",
        "        y_train_pred = best_model.predict(X_train_fold)\n",
        "        y_test_pred = best_model.predict(X_test_fold)\n",
        "\n",
        "        y_train_prob = best_model.predict_proba(X_train_fold)[:, 1]\n",
        "        y_test_prob = best_model.predict_proba(X_test_fold)[:, 1]\n",
        "\n",
        "        # Metrics\n",
        "        test_metrics = {\n",
        "            \"acc\": accuracy_score(y_test_fold, y_test_pred),\n",
        "            \"prec\": precision_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"rec\": recall_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"f1\": f1_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"auc\": roc_auc_score(y_test_fold, y_test_prob)\n",
        "        }\n",
        "\n",
        "        print(f\"‚Üí Accuracy: {test_metrics['acc']:.3f} | F1: {test_metrics['f1']:.3f} | AUC: {test_metrics['auc']:.3f}\")\n",
        "\n",
        "        # Confusion matrices\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        sns.heatmap(confusion_matrix(y_train_fold, y_train_pred), annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
        "        ax[0].set_title(f'{clf_name} - Fold {fold_number} - Train')\n",
        "\n",
        "        sns.heatmap(confusion_matrix(y_test_fold, y_test_pred), annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
        "        ax[1].set_title(f'{clf_name} - Fold {fold_number} - Test')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # ROC Curves\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        RocCurveDisplay.from_estimator(best_model, X_train_fold, y_train_fold, ax=ax[0])\n",
        "        ax[0].set_title(f\"{clf_name} - ROC (Train) - Fold {fold_number}\")\n",
        "        RocCurveDisplay.from_estimator(best_model, X_test_fold, y_test_fold, ax=ax[1])\n",
        "        ax[1].set_title(f\"{clf_name} - ROC (Test) - Fold {fold_number}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Save to same CSV\n",
        "        fold_metrics[\"Classifier\"].append(clf_name)\n",
        "        fold_metrics[\"Fold\"].append(fold_number)\n",
        "        fold_metrics[\"Accuracy\"].append(test_metrics[\"acc\"])\n",
        "        fold_metrics[\"Precision\"].append(test_metrics[\"prec\"])\n",
        "        fold_metrics[\"Recall\"].append(test_metrics[\"rec\"])\n",
        "        fold_metrics[\"F1 Score\"].append(test_metrics[\"f1\"])\n",
        "        fold_metrics[\"AUC ROC\"].append(test_metrics[\"auc\"])\n",
        "\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Train\", y_train_fold, y_train_pred, X_train_fold, y_train_fold, y_train_prob)\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Test\", y_test_fold, y_test_pred, X_test_fold, y_test_fold, y_test_prob)\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "# Save combined results\n",
        "results_df.to_csv(\"churn_classifiers_output.csv\", index=False)\n",
        "print(\"\\n‚úÖ All results (including XGBoost and GBM) saved to churn_classifiers_output.csv\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "d4WgjPefcgcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1: Added neural network\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, confusion_matrix, RocCurveDisplay\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# For logging results\n",
        "nn_results = []\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "fold_number = 1\n",
        "for train_index, test_index in skf.split(X_scaled, y):\n",
        "    print(f\"\\nüß† Neural Network - Fold {fold_number}\")\n",
        "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Model definition\n",
        "    model = Sequential([\n",
        "        Dense(256, activation='relu', input_shape=(X_train_fold.shape[1],)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0,2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0005),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "\n",
        "    # Training\n",
        "    history = model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        validation_split=0.2,\n",
        "        epochs=50,\n",
        "        batch_size=64,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    print(f\"Epochs trained: {len(history.history['loss'])}\")\n",
        "\n",
        "    # Predictions\n",
        "    y_test_prob = model.predict(X_test_fold).flatten()\n",
        "    y_test_pred = (y_test_prob > 0.5).astype(int)\n",
        "\n",
        "    # Evaluation\n",
        "    acc = accuracy_score(y_test_fold, y_test_pred)\n",
        "    prec = precision_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "    rec = recall_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_test_fold, y_test_prob)\n",
        "\n",
        "    print(f\"‚Üí Accuracy: {acc:.3f} | F1: {f1:.3f} | AUC: {auc:.3f}\")\n",
        "\n",
        "    # Log results\n",
        "    nn_results.append({\n",
        "        \"Classifier\": \"NeuralNetwork\",\n",
        "        \"Fold\": fold_number,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1 Score\": f1,\n",
        "        \"AUC ROC\": auc\n",
        "    })\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test_fold, y_test_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"NN - Confusion Matrix - Fold {fold_number}\")\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    RocCurveDisplay.from_predictions(y_test_fold, y_test_prob)\n",
        "    plt.title(f\"NN - ROC Curve - Fold {fold_number}\")\n",
        "    plt.show()\n",
        "\n",
        "    fold_number += 1\n",
        "    # Plot Accuracy\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Convert to DataFrame if needed\n",
        "import pandas as pd\n",
        "nn_results_df = pd.DataFrame(nn_results)\n",
        "print(\"\\nüìä Neural Network Evaluation (Average Across Folds):\")\n",
        "print(nn_results_df.groupby(\"Classifier\").mean(numeric_only=True).round(3))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nL759uoHdCOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the neural network architecture\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the model architecture (no training)\n",
        "model = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(58,), name=\"Dense (256)\"),\n",
        "    BatchNormalization(name=\"BatchNorm\"),\n",
        "    Dropout(0.3, name=\"Dropout_0.3\"),\n",
        "    Dense(128, activation='relu', name=\"Dense (128)\"),\n",
        "    Dropout(0.2, name=\"Dropout_0.2\"),\n",
        "    Dense(64, activation='relu', name=\"Dense (64)\"),\n",
        "    Dense(1, activation='sigmoid', name=\"Output_Sigmoid\")\n",
        "])\n",
        "\n",
        "# Plot and save the model architecture diagram\n",
        "plot_model(model, to_file=\"nn_architecture.png\", show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Display the image in notebook (optional)\n",
        "import IPython.display as display\n",
        "display.Image(\"nn_architecture.png\")\n",
        "model.save(\"nn_model.h5\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-dQZt3QjMfFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner --upgrade"
      ],
      "metadata": {
        "id": "IW5z8zKnJmS7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras tuner parameter optimization for neural network\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Build model with tunable hyperparameters\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    # Input layer\n",
        "    model.add(Dense(\n",
        "        units=hp.Int('units_input', min_value=64, max_value=512, step=64),\n",
        "        activation='relu',\n",
        "        input_shape=(X_scaled.shape[1],)\n",
        "    ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(hp.Float('dropout_input', 0.0, 0.5, step=0.1)))\n",
        "\n",
        "    # Hidden layers: up to 5\n",
        "    for i in range(hp.Int('num_layers', 1, 5)):\n",
        "        model.add(Dense(\n",
        "            units=hp.Int(f'units_{i}', min_value=32, max_value=256, step=32),\n",
        "            activation='relu'\n",
        "        ))\n",
        "        model.add(Dropout(hp.Float(f'dropout_{i}', 0.0, 0.5, step=0.1)))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=Adam(\n",
        "            learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 5e-4, 1e-4])\n",
        "        ),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Define tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=15,\n",
        "    executions_per_trial=1,\n",
        "    directory='nn_tuning',\n",
        "    project_name='churn_tuning'\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Run search\n",
        "tuner.search(\n",
        "    X_scaled, y,\n",
        "    epochs=30,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Retrieve and summarize best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_hyperparams = tuner.get_best_hyperparameters(1)[0]\n",
        "print(\"\\n‚úÖ Best hyperparameters found:\")\n",
        "for param in best_hyperparams.values:\n",
        "    print(f\"{param}: {best_hyperparams.get(param)}\")\n"
      ],
      "metadata": {
        "id": "mQAZYqyAI6xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NN   KERAS TUNER  PARAMETERS OPTIMIZATION (recall)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras_tuner as kt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Build model with tunable hyperparameters\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    # Input layer\n",
        "    model.add(Dense(\n",
        "        units=hp.Int('units_input', min_value=64, max_value=512, step=64),\n",
        "        activation='relu',\n",
        "        input_shape=(X_scaled.shape[1],)\n",
        "    ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(hp.Float('dropout_input', 0.0, 0.5, step=0.1)))\n",
        "\n",
        "    # Hidden layers: up to 5\n",
        "    for i in range(hp.Int('num_layers', 1, 5)):\n",
        "        model.add(Dense(\n",
        "            units=hp.Int(f'units_{i}', min_value=32, max_value=256, step=32),\n",
        "            activation='relu'\n",
        "        ))\n",
        "        model.add(Dropout(hp.Float(f'dropout_{i}', 0.0, 0.5, step=0.1)))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=Adam(\n",
        "            learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 5e-4, 1e-4])\n",
        "        ),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[tf.keras.metrics.Recall(name='recall')]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Define tuner\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective=kt.Objective(\"val_recall\", direction=\"max\"),\n",
        "    max_trials=15,\n",
        "    executions_per_trial=1,\n",
        "    directory='nn_tuning',\n",
        "    project_name='churn_tuning'\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Run search\n",
        "tuner.search(\n",
        "    X_scaled, y,\n",
        "    epochs=30,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Retrieve and summarize best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_hyperparams = tuner.get_best_hyperparameters(1)[0]\n",
        "print(\"\\n‚úÖ Best hyperparameters found:\")\n",
        "for param in best_hyperparams.values:\n",
        "    print(f\"{param}: {best_hyperparams.get(param)}\")\n"
      ],
      "metadata": {
        "id": "NaAP9drYz1mL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ NEURAL NETWORK EXP (RECALL-TUNED FULL PARAM SET ACROSS 4 FOLDS)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Log results\n",
        "nn_results = []\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Stratified K-Fold\n",
        "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "fold_number = 1\n",
        "\n",
        "for train_index, test_index in skf.split(X_scaled, y):\n",
        "    print(f\"\\nüß† Neural Network - Fold {fold_number}\")\n",
        "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Model with ALL recall-tuned hyperparameters\n",
        "    model = Sequential()\n",
        "    # Input layer\n",
        "    model.add(Dense(192, activation='relu', input_shape=(X_train_fold.shape[1],)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Only 1 hidden layer as per 'num_layers'\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.0))\n",
        "\n",
        "    # Remaining hidden layers (not used but retained for clarity)\n",
        "    model.add(Dense(224, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(224, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(192, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.Recall(name='recall')]\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "\n",
        "    # Training\n",
        "    history = model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        validation_split=0.2,\n",
        "        epochs=50,\n",
        "        batch_size=64,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Predictions\n",
        "    y_test_prob = model.predict(X_test_fold).flatten()\n",
        "    y_test_pred = (y_test_prob > 0.5).astype(int)\n",
        "\n",
        "    # Evaluation\n",
        "    acc = accuracy_score(y_test_fold, y_test_pred)\n",
        "    prec = precision_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "    rec = recall_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_test_fold, y_test_prob)\n",
        "\n",
        "    print(f\"‚Üí Accuracy: {acc:.3f} | F1: {f1:.3f} | AUC: {auc:.3f}\")\n",
        "\n",
        "    # Log results\n",
        "    nn_results.append({\n",
        "        \"Classifier\": \"NeuralNetwork_RecallTuned_FullLayers\",\n",
        "        \"Fold\": fold_number,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1 Score\": f1,\n",
        "        \"AUC ROC\": auc\n",
        "    })\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test_fold, y_test_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"NN - Confusion Matrix - Fold {fold_number}\")\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    RocCurveDisplay.from_predictions(y_test_fold, y_test_prob)\n",
        "    plt.title(f\"NN - ROC Curve - Fold {fold_number}\")\n",
        "    plt.show()\n",
        "\n",
        "    # Accuracy & Loss Plots\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "# Results summary\n",
        "nn_results_df = pd.DataFrame(nn_results)\n",
        "print(\"\\nüìä Neural Network Evaluation (Average Across Folds):\")\n",
        "print(nn_results_df.groupby(\"Classifier\").mean(numeric_only=True).round(3))\n"
      ],
      "metadata": {
        "id": "E_n_HKRmR9dO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NN OPTIMIZED\n",
        "# Build final model with best hyperparameters (accuracy)\n",
        "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "\n",
        "final_model = build_model(best_hp)\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=8,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = final_model.fit(\n",
        "    X_train_fold, y_train_fold,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Predict and evaluate\n",
        "y_test_prob = final_model.predict(X_test_fold).flatten()\n",
        "y_test_pred = (y_test_prob > 0.5).astype(int)\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "\n",
        "# Compute metrics\n",
        "acc = accuracy_score(y_test_fold, y_test_pred)\n",
        "prec = precision_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "rec = recall_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "f1 = f1_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "auc = roc_auc_score(y_test_fold, y_test_prob)\n",
        "\n",
        "print(f\"\\n‚úÖ Final Model Evaluation:\")\n",
        "print(f\"Accuracy: {acc:.3f} | Precision: {prec:.3f} | Recall: {rec:.3f} | F1: {f1:.3f} | AUC: {auc:.3f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test_fold, y_test_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Final Model - Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "RocCurveDisplay.from_predictions(y_test_fold, y_test_prob)\n",
        "plt.title(\"Final Model - ROC Curve\")\n",
        "plt.show()\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "528gpryMe63V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2: Added cost-sensitive learning (class weighting)\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "\n",
        "# Initialize results storage\n",
        "results_df = pd.DataFrame(columns=[\n",
        "    \"Classifier Name\", \"Fold\", \"TrainOrTest\",\n",
        "    \"Num Train Samples\", \"Num Churned in Train\",\n",
        "    \"TP\", \"TN\", \"FP\", \"FN\", \"ROC-AUC\"\n",
        "])\n",
        "\n",
        "fold_metrics = {\n",
        "    \"Classifier\": [], \"Fold\": [],\n",
        "    \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 Score\": [], \"AUC ROC\": []\n",
        "}\n",
        "\n",
        "# Logging function\n",
        "def log_metrics_to_df(df, classifier_name, fold_number, dataset_type, y_true, y_pred, X_data, y_data, y_prob):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "    roc_auc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
        "    row = {\n",
        "        \"Classifier Name\": classifier_name,\n",
        "        \"Fold\": fold_number,\n",
        "        \"TrainOrTest\": dataset_type,\n",
        "        \"Num Train Samples\": len(X_data),\n",
        "        \"Num Churned in Train\": sum(y_data == 1),\n",
        "        \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
        "        \"ROC-AUC\": roc_auc\n",
        "    }\n",
        "    return pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "\n",
        "# Classifiers (some with class_weight balanced)\n",
        "classifiers_and_params = {\n",
        "    \"kNN\": (\n",
        "        KNeighborsClassifier(),\n",
        "        {\n",
        "            \"n_neighbors\": randint(1, 50),\n",
        "            \"weights\": [\"uniform\", \"distance\"],\n",
        "            \"p\": [1, 2]\n",
        "        }\n",
        "    ),\n",
        "    \"LDA\": (\n",
        "        LinearDiscriminantAnalysis(),\n",
        "        [\n",
        "            {\"solver\": [\"svd\"], \"shrinkage\": [None], \"tol\": uniform(1e-5, 1e-2)},\n",
        "            {\"solver\": [\"lsqr\", \"eigen\"], \"shrinkage\": [None, \"auto\"], \"tol\": uniform(1e-5, 1e-2)}\n",
        "        ]\n",
        "    ),\n",
        "    \"LogReg\": (\n",
        "        LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced'),\n",
        "        {\n",
        "            \"C\": uniform(0.01, 10),\n",
        "            \"penalty\": [\"l1\", \"l2\"],\n",
        "            \"solver\": [\"liblinear\", \"saga\"]\n",
        "        }\n",
        "    ),\n",
        "    \"DecisionTree\": (\n",
        "        DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
        "        {\n",
        "            \"max_depth\": randint(1, 20),\n",
        "            \"min_samples_split\": randint(2, 10),\n",
        "            \"min_samples_leaf\": randint(1, 10),\n",
        "            \"criterion\": [\"gini\", \"entropy\"]\n",
        "        }\n",
        "    ),\n",
        "    \"RandomForest\": (\n",
        "        RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
        "        {\n",
        "            \"n_estimators\": randint(50, 300),\n",
        "            \"max_depth\": randint(1, 20),\n",
        "            \"min_samples_split\": randint(2, 10),\n",
        "            \"min_samples_leaf\": randint(1, 10),\n",
        "            \"criterion\": [\"gini\", \"entropy\"]\n",
        "        }\n",
        "    ),\n",
        "    \"NaiveBayes\": (\n",
        "        GaussianNB(),\n",
        "        {\n",
        "            \"var_smoothing\": uniform(1e-9, 1e-5)\n",
        "        }\n",
        "    ),\n",
        "    \"AdaBoost\": (\n",
        "        AdaBoostClassifier(random_state=42),\n",
        "        {\n",
        "            \"n_estimators\": randint(50, 300),\n",
        "            \"learning_rate\": uniform(0.01, 0.5)\n",
        "        }\n",
        "    )\n",
        "}\n",
        "# Begin loop\n",
        "fold_number = 1\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train_fold = X.iloc[train_index]\n",
        "    X_test_fold = X.iloc[test_index]\n",
        "    y_train_fold = y.iloc[train_index]\n",
        "    y_test_fold = y.iloc[test_index]\n",
        "\n",
        "    for clf_name, (clf_base, param_dist) in classifiers_and_params.items():\n",
        "        print(f\"\\nüîç {clf_name} on Fold {fold_number}\")\n",
        "\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=clf_base,\n",
        "            param_distributions=param_dist,\n",
        "            n_iter=10,\n",
        "            scoring=\"f1\",\n",
        "            cv=3,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        random_search.fit(X_train_fold, y_train_fold)\n",
        "        best_model = random_search.best_estimator_\n",
        "        print(\"Best params:\", random_search.best_params_)\n",
        "\n",
        "        y_train_pred = best_model.predict(X_train_fold)\n",
        "        y_test_pred = best_model.predict(X_test_fold)\n",
        "\n",
        "        y_train_prob = best_model.predict_proba(X_train_fold)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
        "        y_test_prob = best_model.predict_proba(X_test_fold)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
        "\n",
        "        # Evaluation\n",
        "        test_metrics = {\n",
        "            \"acc\": accuracy_score(y_test_fold, y_test_pred),\n",
        "            \"prec\": precision_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"rec\": recall_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"f1\": f1_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"auc\": roc_auc_score(y_test_fold, y_test_prob) if y_test_prob is not None else 0.0\n",
        "        }\n",
        "\n",
        "        print(f\"‚Üí Accuracy: {test_metrics['acc']:.3f} | F1: {test_metrics['f1']:.3f} | AUC: {test_metrics['auc']:.3f}\")\n",
        "\n",
        "        # Confusion Matrices\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        sns.heatmap(confusion_matrix(y_train_fold, y_train_pred), annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
        "        ax[0].set_title(f'{clf_name} - Fold {fold_number} - Train')\n",
        "\n",
        "        sns.heatmap(confusion_matrix(y_test_fold, y_test_pred), annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
        "        ax[1].set_title(f'{clf_name} - Fold {fold_number} - Test')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # ROC Curve\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        if y_train_prob is not None:\n",
        "            RocCurveDisplay.from_estimator(best_model, X_train_fold, y_train_fold, ax=ax[0])\n",
        "            ax[0].set_title(f\"{clf_name} - ROC (Train) - Fold {fold_number}\")\n",
        "        if y_test_prob is not None:\n",
        "            RocCurveDisplay.from_estimator(best_model, X_test_fold, y_test_fold, ax=ax[1])\n",
        "            ax[1].set_title(f\"{clf_name} - ROC (Test) - Fold {fold_number}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Save metrics\n",
        "        fold_metrics[\"Classifier\"].append(clf_name)\n",
        "        fold_metrics[\"Fold\"].append(fold_number)\n",
        "        fold_metrics[\"Accuracy\"].append(test_metrics[\"acc\"])\n",
        "        fold_metrics[\"Precision\"].append(test_metrics[\"prec\"])\n",
        "        fold_metrics[\"Recall\"].append(test_metrics[\"rec\"])\n",
        "        fold_metrics[\"F1 Score\"].append(test_metrics[\"f1\"])\n",
        "        fold_metrics[\"AUC ROC\"].append(test_metrics[\"auc\"])\n",
        "\n",
        "        # Detailed logs\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Train\", y_train_fold, y_train_pred, X_train_fold, y_train_fold, y_train_prob)\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Test\", y_test_fold, y_test_pred, X_test_fold, y_test_fold, y_test_prob)\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "# Summary\n",
        "print(\"\\nüìä Final Summary by Classifier (Average Across Folds):\")\n",
        "summary_df = pd.DataFrame(fold_metrics)\n",
        "grouped = summary_df.groupby(\"Classifier\")\n",
        "print(grouped.mean(numeric_only=True).round(3))\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv(\"churn_classifiers_output.csv\", index=False)\n",
        "print(\"\\n‚úÖ All results saved to churn_classifiers_output.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FpWmgLXq6GJ4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2: Added 2 classifiers (boosters)\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "\n",
        "\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Initialize logs\n",
        "results_df = pd.DataFrame(columns=[\n",
        "    \"Classifier Name\", \"Fold\", \"TrainOrTest\",\n",
        "    \"Num Train Samples\", \"Num Churned in Train\",\n",
        "    \"TP\", \"TN\", \"FP\", \"FN\", \"ROC-AUC\"\n",
        "])\n",
        "\n",
        "fold_metrics = {\n",
        "    \"Classifier\": [], \"Fold\": [],\n",
        "    \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 Score\": [], \"AUC ROC\": []\n",
        "}\n",
        "\n",
        "def log_metrics_to_df(df, classifier_name, fold_number, dataset_type, y_true, y_pred, X_data, y_data, y_prob):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "    roc_auc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
        "    row = {\n",
        "        \"Classifier Name\": classifier_name,\n",
        "        \"Fold\": fold_number,\n",
        "        \"TrainOrTest\": dataset_type,\n",
        "        \"Num Train Samples\": len(X_data),\n",
        "        \"Num Churned in Train\": sum(y_data == 1),\n",
        "        \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
        "        \"ROC-AUC\": roc_auc\n",
        "    }\n",
        "    return pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "   # Estimate class weight for scale_pos_weight\n",
        "neg, pos = (y == 0).sum(), (y == 1).sum()\n",
        "scale_pos_weight = neg / pos\n",
        "extra_classifiers = {\n",
        "\n",
        "    \"XGBoost\": (\n",
        "        XGBClassifier(\n",
        "            use_label_encoder=False,\n",
        "            eval_metric='logloss',\n",
        "            random_state=42,\n",
        "            n_jobs=-1,  # Parallelization\n",
        "            scale_pos_weight=scale_pos_weight  # Handles class imbalance\n",
        "        ),\n",
        "        {\n",
        "            \"n_estimators\": randint(100, 300),\n",
        "            \"max_depth\": randint(3, 10),\n",
        "            \"learning_rate\": uniform(0.01, 0.3),\n",
        "            \"subsample\": uniform(0.6, 0.4),\n",
        "            \"colsample_bytree\": uniform(0.6, 0.4),\n",
        "            \"reg_alpha\": uniform(0.1, 1.0),    # L1 regularization\n",
        "            \"reg_lambda\": uniform(1.0, 3.0)    # L2 regularization\n",
        "        }\n",
        "    ),\n",
        "    \"GradientBoosting\": (\n",
        "        GradientBoostingClassifier(\n",
        "            random_state=42\n",
        "        ),\n",
        "        {\n",
        "            \"n_estimators\": randint(100, 300),\n",
        "            \"max_depth\": randint(3, 10),\n",
        "            \"learning_rate\": uniform(0.01, 0.3),\n",
        "            \"subsample\": uniform(0.6, 0.4),\n",
        "            \"min_samples_split\": randint(2, 10),  # Regularization\n",
        "            \"min_samples_leaf\": randint(1, 10),   # Regularization\n",
        "            \"max_features\": [\"auto\", \"sqrt\", \"log2\"]  # Feature usage regularization\n",
        "        }\n",
        "    )\n",
        "}\n",
        "fold_number = 1\n",
        "# New experiments loop\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train_fold = X.iloc[train_index]\n",
        "    X_test_fold = X.iloc[test_index]\n",
        "    y_train_fold = y.iloc[train_index]\n",
        "    y_test_fold = y.iloc[test_index]\n",
        "\n",
        "    for clf_name, (clf_base, param_dist) in extra_classifiers.items():\n",
        "        print(f\"\\nüîç {clf_name} on Fold {fold_number}\")\n",
        "\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=clf_base,\n",
        "            param_distributions=param_dist,\n",
        "            n_iter=10,\n",
        "            scoring=\"f1\",\n",
        "            cv=3,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        random_search.fit(X_train_fold, y_train_fold)\n",
        "        best_model = random_search.best_estimator_\n",
        "        print(\"Best params:\", random_search.best_params_)\n",
        "\n",
        "        y_train_pred = best_model.predict(X_train_fold)\n",
        "        y_test_pred = best_model.predict(X_test_fold)\n",
        "\n",
        "        y_train_prob = best_model.predict_proba(X_train_fold)[:, 1]\n",
        "        y_test_prob = best_model.predict_proba(X_test_fold)[:, 1]\n",
        "\n",
        "        # Metrics\n",
        "        test_metrics = {\n",
        "            \"acc\": accuracy_score(y_test_fold, y_test_pred),\n",
        "            \"prec\": precision_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"rec\": recall_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"f1\": f1_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"auc\": roc_auc_score(y_test_fold, y_test_prob)\n",
        "        }\n",
        "\n",
        "        print(f\"‚Üí Accuracy: {test_metrics['acc']:.3f} | F1: {test_metrics['f1']:.3f} | AUC: {test_metrics['auc']:.3f}\")\n",
        "\n",
        "        # Confusion matrices\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        sns.heatmap(confusion_matrix(y_train_fold, y_train_pred), annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
        "        ax[0].set_title(f'{clf_name} - Fold {fold_number} - Train')\n",
        "\n",
        "        sns.heatmap(confusion_matrix(y_test_fold, y_test_pred), annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
        "        ax[1].set_title(f'{clf_name} - Fold {fold_number} - Test')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # ROC Curves\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        RocCurveDisplay.from_estimator(best_model, X_train_fold, y_train_fold, ax=ax[0])\n",
        "        ax[0].set_title(f\"{clf_name} - ROC (Train) - Fold {fold_number}\")\n",
        "        RocCurveDisplay.from_estimator(best_model, X_test_fold, y_test_fold, ax=ax[1])\n",
        "        ax[1].set_title(f\"{clf_name} - ROC (Test) - Fold {fold_number}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Save to same CSV\n",
        "        fold_metrics[\"Classifier\"].append(clf_name)\n",
        "        fold_metrics[\"Fold\"].append(fold_number)\n",
        "        fold_metrics[\"Accuracy\"].append(test_metrics[\"acc\"])\n",
        "        fold_metrics[\"Precision\"].append(test_metrics[\"prec\"])\n",
        "        fold_metrics[\"Recall\"].append(test_metrics[\"rec\"])\n",
        "        fold_metrics[\"F1 Score\"].append(test_metrics[\"f1\"])\n",
        "        fold_metrics[\"AUC ROC\"].append(test_metrics[\"auc\"])\n",
        "\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Train\", y_train_fold, y_train_pred, X_train_fold, y_train_fold, y_train_prob)\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Test\", y_test_fold, y_test_pred, X_test_fold, y_test_fold, y_test_prob)\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "# Save combined results\n",
        "results_df.to_csv(\"churn_classifiers_output.csv\", index=False)\n",
        "print(\"\\n‚úÖ All results (including XGBoost and GBM) saved to churn_classifiers_output.csv\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MRRJT-SxqEAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2 Neural Network\n",
        "# NEURAL NETWORK EXP2 ‚Äì Cost-Sensitive Learning (Class Weighting)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# For logging results\n",
        "nn_results = []\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "fold_number = 1\n",
        "for train_index, test_index in skf.split(X_scaled, y):\n",
        "    print(f\"\\nüß† Neural Network (Class Weighted) - Fold {fold_number}\")\n",
        "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Compute class weights based on training fold\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.array([0, 1]),\n",
        "        y=y_train_fold\n",
        "    )\n",
        "    class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
        "    print(f\"Class Weights: {class_weights_dict}\")\n",
        "\n",
        "    # Model definition\n",
        "    model = Sequential([\n",
        "        Dense(256, activation='relu', input_shape=(X_train_fold.shape[1],)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0005),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "\n",
        "    # Training\n",
        "    history = model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        validation_split=0.2,\n",
        "        epochs=50,\n",
        "        batch_size=64,\n",
        "        class_weight=class_weights_dict,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    print(f\"Epochs trained: {len(history.history['loss'])}\")\n",
        "\n",
        "    # Predictions\n",
        "    y_test_prob = model.predict(X_test_fold).flatten()\n",
        "    y_test_pred = (y_test_prob > 0.5).astype(int)\n",
        "\n",
        "    # Evaluation\n",
        "    acc = accuracy_score(y_test_fold, y_test_pred)\n",
        "    prec = precision_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "    rec = recall_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_test_fold, y_test_prob)\n",
        "\n",
        "    print(f\"‚Üí Accuracy: {acc:.3f} | F1: {f1:.3f} | AUC: {auc:.3f}\")\n",
        "\n",
        "    # Log results\n",
        "    nn_results.append({\n",
        "        \"Classifier\": \"NeuralNetwork_Weighted\",\n",
        "        \"Fold\": fold_number,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1 Score\": f1,\n",
        "        \"AUC ROC\": auc\n",
        "    })\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test_fold, y_test_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"NN (Weighted) - Confusion Matrix - Fold {fold_number}\")\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    RocCurveDisplay.from_predictions(y_test_fold, y_test_prob)\n",
        "    plt.title(f\"NN (Weighted) - ROC Curve - Fold {fold_number}\")\n",
        "    plt.show()\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "# Plot Accuracy and Loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Convert to DataFrame if needed\n",
        "nn_results_df = pd.DataFrame(nn_results)\n",
        "print(\"\\nüìä Neural Network (Weighted) Evaluation (Average Across Folds):\")\n",
        "print(nn_results_df.groupby(\"Classifier\").mean(numeric_only=True).round(3))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RRaEEwHx6oW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment 3\n",
        "#Scoring=recall as hyperparameter optimization metric\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "\n",
        "# Initialize results storage\n",
        "results_df = pd.DataFrame(columns=[\n",
        "    \"Classifier Name\", \"Fold\", \"TrainOrTest\",\n",
        "    \"Num Train Samples\", \"Num Churned in Train\",\n",
        "    \"TP\", \"TN\", \"FP\", \"FN\", \"ROC-AUC\"\n",
        "])\n",
        "\n",
        "fold_metrics = {\n",
        "    \"Classifier\": [], \"Fold\": [],\n",
        "    \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 Score\": [], \"AUC ROC\": []\n",
        "}\n",
        "\n",
        "# Logging function\n",
        "def log_metrics_to_df(df, classifier_name, fold_number, dataset_type, y_true, y_pred, X_data, y_data, y_prob):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "    roc_auc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
        "    row = {\n",
        "        \"Classifier Name\": classifier_name,\n",
        "        \"Fold\": fold_number,\n",
        "        \"TrainOrTest\": dataset_type,\n",
        "        \"Num Train Samples\": len(X_data),\n",
        "        \"Num Churned in Train\": sum(y_data == 1),\n",
        "        \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
        "        \"ROC-AUC\": roc_auc\n",
        "    }\n",
        "    return pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "\n",
        "# Classifiers (some with class_weight balanced)\n",
        "classifiers_and_params = {\n",
        "    \"kNN\": (\n",
        "        KNeighborsClassifier(),\n",
        "        {\n",
        "            \"n_neighbors\": randint(1, 200),\n",
        "            \"weights\": [\"uniform\", \"distance\"],\n",
        "            \"p\": [1, 2]\n",
        "        }\n",
        "    ),\n",
        "    \"LDA\": (\n",
        "        LinearDiscriminantAnalysis(),\n",
        "        [\n",
        "            {\"solver\": [\"svd\"], \"shrinkage\": [None], \"tol\": uniform(1e-5, 1e-2)},\n",
        "            {\"solver\": [\"lsqr\", \"eigen\"], \"shrinkage\": [None, \"auto\"], \"tol\": uniform(1e-5, 1e-2)}\n",
        "        ]\n",
        "    ),\n",
        "    \"LogReg\": (\n",
        "        LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced'),\n",
        "        {\n",
        "            \"C\": uniform(0.01, 10),\n",
        "            \"penalty\": [\"l1\", \"l2\"],\n",
        "            \"solver\": [\"liblinear\", \"saga\"]\n",
        "        }\n",
        "    ),\n",
        "    \"DecisionTree\": (\n",
        "        DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
        "        {\n",
        "            \"max_depth\": randint(1, 20),\n",
        "            \"min_samples_split\": randint(2, 10),\n",
        "            \"min_samples_leaf\": randint(1, 10),\n",
        "            \"criterion\": [\"gini\", \"entropy\"]\n",
        "        }\n",
        "    ),\n",
        "    \"RandomForest\": (\n",
        "        RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
        "        {\n",
        "            \"n_estimators\": randint(50, 300),\n",
        "            \"max_depth\": randint(1, 20),\n",
        "            \"min_samples_split\": randint(2, 10),\n",
        "            \"min_samples_leaf\": randint(1, 10),\n",
        "            \"criterion\": [\"gini\", \"entropy\"]\n",
        "        }\n",
        "    ),\n",
        "    \"NaiveBayes\": (\n",
        "        GaussianNB(),\n",
        "        {\n",
        "            \"var_smoothing\": uniform(1e-9, 1e-5)\n",
        "        }\n",
        "    ),\n",
        "    \"AdaBoost\": (\n",
        "        AdaBoostClassifier(random_state=42),\n",
        "        {\n",
        "            \"n_estimators\": randint(50, 300),\n",
        "            \"learning_rate\": uniform(0.01, 0.5)\n",
        "        }\n",
        "    )\n",
        "}\n",
        "# Begin loop\n",
        "fold_number = 1\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train_fold = X.iloc[train_index]\n",
        "    X_test_fold = X.iloc[test_index]\n",
        "    y_train_fold = y.iloc[train_index]\n",
        "    y_test_fold = y.iloc[test_index]\n",
        "\n",
        "    for clf_name, (clf_base, param_dist) in classifiers_and_params.items():\n",
        "        print(f\"\\nüîç {clf_name} on Fold {fold_number}\")\n",
        "\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=clf_base,\n",
        "            param_distributions=param_dist,\n",
        "            n_iter=30,\n",
        "            scoring=\"recall\",\n",
        "            cv=3,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        random_search.fit(X_train_fold, y_train_fold)\n",
        "        best_model = random_search.best_estimator_\n",
        "        print(\"Best params:\", random_search.best_params_)\n",
        "\n",
        "        y_train_pred = best_model.predict(X_train_fold)\n",
        "        y_test_pred = best_model.predict(X_test_fold)\n",
        "\n",
        "        y_train_prob = best_model.predict_proba(X_train_fold)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
        "        y_test_prob = best_model.predict_proba(X_test_fold)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
        "\n",
        "        # Evaluation\n",
        "        test_metrics = {\n",
        "            \"acc\": accuracy_score(y_test_fold, y_test_pred),\n",
        "            \"prec\": precision_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"rec\": recall_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"f1\": f1_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"auc\": roc_auc_score(y_test_fold, y_test_prob) if y_test_prob is not None else 0.0\n",
        "        }\n",
        "\n",
        "        print(f\"‚Üí Accuracy: {test_metrics['acc']:.3f} | F1: {test_metrics['f1']:.3f} | AUC: {test_metrics['auc']:.3f}\")\n",
        "\n",
        "        # Confusion Matrices\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        sns.heatmap(confusion_matrix(y_train_fold, y_train_pred), annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
        "        ax[0].set_title(f'{clf_name} - Fold {fold_number} - Train')\n",
        "\n",
        "        sns.heatmap(confusion_matrix(y_test_fold, y_test_pred), annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
        "        ax[1].set_title(f'{clf_name} - Fold {fold_number} - Test')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # ROC Curve\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        if y_train_prob is not None:\n",
        "            RocCurveDisplay.from_estimator(best_model, X_train_fold, y_train_fold, ax=ax[0])\n",
        "            ax[0].set_title(f\"{clf_name} - ROC (Train) - Fold {fold_number}\")\n",
        "        if y_test_prob is not None:\n",
        "            RocCurveDisplay.from_estimator(best_model, X_test_fold, y_test_fold, ax=ax[1])\n",
        "            ax[1].set_title(f\"{clf_name} - ROC (Test) - Fold {fold_number}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Save metrics\n",
        "        fold_metrics[\"Classifier\"].append(clf_name)\n",
        "        fold_metrics[\"Fold\"].append(fold_number)\n",
        "        fold_metrics[\"Accuracy\"].append(test_metrics[\"acc\"])\n",
        "        fold_metrics[\"Precision\"].append(test_metrics[\"prec\"])\n",
        "        fold_metrics[\"Recall\"].append(test_metrics[\"rec\"])\n",
        "        fold_metrics[\"F1 Score\"].append(test_metrics[\"f1\"])\n",
        "        fold_metrics[\"AUC ROC\"].append(test_metrics[\"auc\"])\n",
        "\n",
        "        # Detailed logs\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Train\", y_train_fold, y_train_pred, X_train_fold, y_train_fold, y_train_prob)\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Test\", y_test_fold, y_test_pred, X_test_fold, y_test_fold, y_test_prob)\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "# Summary\n",
        "print(\"\\nüìä Final Summary by Classifier (Average Across Folds):\")\n",
        "summary_df = pd.DataFrame(fold_metrics)\n",
        "grouped = summary_df.groupby(\"Classifier\")\n",
        "print(grouped.mean(numeric_only=True).round(3))\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv(\"churn_classifiers_output.csv\", index=False)\n",
        "print(\"\\n‚úÖ All results saved to churn_classifiers_output.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IULaMhfWay3H",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 3 boosting classifiers\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "\n",
        "\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Initialize logs\n",
        "results_df = pd.DataFrame(columns=[\n",
        "    \"Classifier Name\", \"Fold\", \"TrainOrTest\",\n",
        "    \"Num Train Samples\", \"Num Churned in Train\",\n",
        "    \"TP\", \"TN\", \"FP\", \"FN\", \"ROC-AUC\"\n",
        "])\n",
        "\n",
        "fold_metrics = {\n",
        "    \"Classifier\": [], \"Fold\": [],\n",
        "    \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 Score\": [], \"AUC ROC\": []\n",
        "}\n",
        "\n",
        "def log_metrics_to_df(df, classifier_name, fold_number, dataset_type, y_true, y_pred, X_data, y_data, y_prob):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "    roc_auc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
        "    row = {\n",
        "        \"Classifier Name\": classifier_name,\n",
        "        \"Fold\": fold_number,\n",
        "        \"TrainOrTest\": dataset_type,\n",
        "        \"Num Train Samples\": len(X_data),\n",
        "        \"Num Churned in Train\": sum(y_data == 1),\n",
        "        \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
        "        \"ROC-AUC\": roc_auc\n",
        "    }\n",
        "    return pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "   # Estimate class weight for scale_pos_weight\n",
        "neg, pos = (y == 0).sum(), (y == 1).sum()\n",
        "scale_pos_weight = neg / pos\n",
        "extra_classifiers = {\n",
        "\n",
        "    \"XGBoost\": (\n",
        "        XGBClassifier(\n",
        "            use_label_encoder=False,\n",
        "            eval_metric='logloss',\n",
        "            random_state=42,\n",
        "            n_jobs=-1,  # Parallelization\n",
        "            scale_pos_weight=scale_pos_weight  # Handles class imbalance\n",
        "        ),\n",
        "        {\n",
        "            \"n_estimators\": randint(100, 300),\n",
        "            \"max_depth\": randint(3, 10),\n",
        "            \"learning_rate\": uniform(0.01, 0.3),\n",
        "            \"subsample\": uniform(0.6, 0.4),\n",
        "            \"colsample_bytree\": uniform(0.6, 0.4),\n",
        "            \"reg_alpha\": uniform(0.1, 1.0),    # L1 regularization\n",
        "            \"reg_lambda\": uniform(1.0, 3.0)    # L2 regularization\n",
        "        }\n",
        "    ),\n",
        "    \"GradientBoosting\": (\n",
        "        GradientBoostingClassifier(\n",
        "            random_state=42\n",
        "        ),\n",
        "        {\n",
        "            \"n_estimators\": randint(100, 300),\n",
        "            \"max_depth\": randint(3, 10),\n",
        "            \"learning_rate\": uniform(0.01, 0.3),\n",
        "            \"subsample\": uniform(0.6, 0.4),\n",
        "            \"min_samples_split\": randint(2, 10),  # Regularization\n",
        "            \"min_samples_leaf\": randint(1, 10),   # Regularization\n",
        "            \"max_features\": [\"auto\", \"sqrt\", \"log2\"]  # Feature usage regularization\n",
        "        }\n",
        "    )\n",
        "}\n",
        "fold_number = 1\n",
        "# New experiments loop\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train_fold = X.iloc[train_index]\n",
        "    X_test_fold = X.iloc[test_index]\n",
        "    y_train_fold = y.iloc[train_index]\n",
        "    y_test_fold = y.iloc[test_index]\n",
        "\n",
        "    for clf_name, (clf_base, param_dist) in extra_classifiers.items():\n",
        "        print(f\"\\nüîç {clf_name} on Fold {fold_number}\")\n",
        "\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=clf_base,\n",
        "            param_distributions=param_dist,\n",
        "            n_iter=30,\n",
        "            scoring=\"recall\",\n",
        "            cv=3,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        random_search.fit(X_train_fold, y_train_fold)\n",
        "        best_model = random_search.best_estimator_\n",
        "        print(\"Best params:\", random_search.best_params_)\n",
        "\n",
        "        y_train_pred = best_model.predict(X_train_fold)\n",
        "        y_test_pred = best_model.predict(X_test_fold)\n",
        "\n",
        "        y_train_prob = best_model.predict_proba(X_train_fold)[:, 1]\n",
        "        y_test_prob = best_model.predict_proba(X_test_fold)[:, 1]\n",
        "\n",
        "        # Metrics\n",
        "        test_metrics = {\n",
        "            \"acc\": accuracy_score(y_test_fold, y_test_pred),\n",
        "            \"prec\": precision_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"rec\": recall_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"f1\": f1_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"auc\": roc_auc_score(y_test_fold, y_test_prob)\n",
        "        }\n",
        "\n",
        "        print(f\"‚Üí Accuracy: {test_metrics['acc']:.3f} | F1: {test_metrics['f1']:.3f} | AUC: {test_metrics['auc']:.3f}\")\n",
        "\n",
        "        # Confusion matrices\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        sns.heatmap(confusion_matrix(y_train_fold, y_train_pred), annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
        "        ax[0].set_title(f'{clf_name} - Fold {fold_number} - Train')\n",
        "\n",
        "        sns.heatmap(confusion_matrix(y_test_fold, y_test_pred), annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
        "        ax[1].set_title(f'{clf_name} - Fold {fold_number} - Test')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # ROC Curves\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        RocCurveDisplay.from_estimator(best_model, X_train_fold, y_train_fold, ax=ax[0])\n",
        "        ax[0].set_title(f\"{clf_name} - ROC (Train) - Fold {fold_number}\")\n",
        "        RocCurveDisplay.from_estimator(best_model, X_test_fold, y_test_fold, ax=ax[1])\n",
        "        ax[1].set_title(f\"{clf_name} - ROC (Test) - Fold {fold_number}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Save to same CSV\n",
        "        fold_metrics[\"Classifier\"].append(clf_name)\n",
        "        fold_metrics[\"Fold\"].append(fold_number)\n",
        "        fold_metrics[\"Accuracy\"].append(test_metrics[\"acc\"])\n",
        "        fold_metrics[\"Precision\"].append(test_metrics[\"prec\"])\n",
        "        fold_metrics[\"Recall\"].append(test_metrics[\"rec\"])\n",
        "        fold_metrics[\"F1 Score\"].append(test_metrics[\"f1\"])\n",
        "        fold_metrics[\"AUC ROC\"].append(test_metrics[\"auc\"])\n",
        "\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Train\", y_train_fold, y_train_pred, X_train_fold, y_train_fold, y_train_prob)\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Test\", y_test_fold, y_test_pred, X_test_fold, y_test_fold, y_test_prob)\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "# Save combined results\n",
        "results_df.to_csv(\"churn_classifiers_output.csv\", index=False)\n",
        "print(\"\\n‚úÖ All results (including XGBoost and GBM) saved to churn_classifiers_output.csv\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qeJngtljq3h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 4 - SMOTE\n",
        "# Create synthetic data for minority class in train\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "smote = SMOTE(random_state=42)\n",
        "# Initialize StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # üü° Apply SMOTE ONLY to the training set\n",
        "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Report distribution\n",
        "    train_counts = y_train.value_counts()\n",
        "    train_percentages = y_train.value_counts(normalize=True) * 100\n",
        "\n",
        "    test_counts = y_test.value_counts()\n",
        "    test_percentages = y_test.value_counts(normalize=True) * 100\n",
        "\n",
        "    print(f\"Fold {fold + 1}:\")\n",
        "    print(\"Training set after SMOTE:\")\n",
        "    print(f\"  Not Churned (0): {train_counts[0]} ({train_percentages[0]:.2f}%)\")\n",
        "    print(f\"  Churned (1): {train_counts[1]} ({train_percentages[1]:.2f}%)\")\n",
        "    print(\"Testing set (original distribution):\")\n",
        "    print(f\"  Not Churned (0): {test_counts[0]} ({test_percentages[0]:.2f}%)\")\n",
        "    print(f\"  Churned (1): {test_counts[1]} ({test_percentages[1]:.2f}%)\")\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "id": "Ubw_dEptCq4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn\n"
      ],
      "metadata": {
        "id": "edYR4eFn-RxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 4 - SMOTE\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Initialize results storage\n",
        "results_df = pd.DataFrame(columns=[\n",
        "    \"Classifier Name\", \"Fold\", \"TrainOrTest\",\n",
        "    \"Num Train Samples\", \"Num Churned in Train\",\n",
        "    \"TP\", \"TN\", \"FP\", \"FN\", \"ROC-AUC\"\n",
        "])\n",
        "\n",
        "fold_metrics = {\n",
        "    \"Classifier\": [], \"Fold\": [],\n",
        "    \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 Score\": [], \"AUC ROC\": []\n",
        "}\n",
        "\n",
        "# Logging function\n",
        "def log_metrics_to_df(df, classifier_name, fold_number, dataset_type, y_true, y_pred, X_data, y_data, y_prob):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "    roc_auc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
        "    row = {\n",
        "        \"Classifier Name\": classifier_name,\n",
        "        \"Fold\": fold_number,\n",
        "        \"TrainOrTest\": dataset_type,\n",
        "        \"Num Train Samples\": len(X_data),\n",
        "        \"Num Churned in Train\": sum(y_data == 1),\n",
        "        \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
        "        \"ROC-AUC\": roc_auc\n",
        "    }\n",
        "    return pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "\n",
        "# Classifiers (some with class_weight balanced)\n",
        "classifiers_and_params = {\n",
        "    \"kNN\": (\n",
        "        KNeighborsClassifier(),\n",
        "        {\n",
        "            \"n_neighbors\": randint(1, 50),\n",
        "            \"weights\": [\"uniform\", \"distance\"],\n",
        "            \"p\": [1, 2]\n",
        "        }\n",
        "    ),\n",
        "    \"LDA\": (\n",
        "        LinearDiscriminantAnalysis(),\n",
        "        [\n",
        "            {\"solver\": [\"svd\"], \"shrinkage\": [None], \"tol\": uniform(1e-5, 1e-2)},\n",
        "            {\"solver\": [\"lsqr\", \"eigen\"], \"shrinkage\": [None, \"auto\"], \"tol\": uniform(1e-5, 1e-2)}\n",
        "        ]\n",
        "    ),\n",
        "    \"LogReg\": (\n",
        "        LogisticRegression(random_state=42, max_iter=1000),\n",
        "        {\n",
        "            \"C\": uniform(0.01, 10),\n",
        "            \"penalty\": [\"l1\", \"l2\"],\n",
        "            \"solver\": [\"liblinear\", \"saga\"]\n",
        "        }\n",
        "    ),\n",
        "    \"DecisionTree\": (\n",
        "        DecisionTreeClassifier(random_state=42),\n",
        "        {\n",
        "            \"max_depth\": randint(1, 20),\n",
        "            \"min_samples_split\": randint(2, 10),\n",
        "            \"min_samples_leaf\": randint(1, 10),\n",
        "            \"criterion\": [\"gini\", \"entropy\"]\n",
        "        }\n",
        "    ),\n",
        "    \"RandomForest\": (\n",
        "        RandomForestClassifier(random_state=42),\n",
        "        {\n",
        "            \"n_estimators\": randint(50, 300),\n",
        "            \"max_depth\": randint(1, 20),\n",
        "            \"min_samples_split\": randint(2, 10),\n",
        "            \"min_samples_leaf\": randint(1, 10),\n",
        "            \"criterion\": [\"gini\", \"entropy\"]\n",
        "        }\n",
        "    ),\n",
        "    \"NaiveBayes\": (\n",
        "        GaussianNB(),\n",
        "        {\n",
        "            \"var_smoothing\": uniform(1e-9, 1e-5)\n",
        "        }\n",
        "    ),\n",
        "    \"AdaBoost\": (\n",
        "        AdaBoostClassifier(random_state=42),\n",
        "        {\n",
        "            \"n_estimators\": randint(50, 300),\n",
        "            \"learning_rate\": uniform(0.01, 0.5)\n",
        "        }\n",
        "    )\n",
        "}\n",
        "# Begin loop\n",
        "fold_number = 1\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    # Apply SMOTE only on training data\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_fold, y_train_fold = smote.fit_resample(X_train_fold, y_train_fold)\n",
        "\n",
        "\n",
        "    for clf_name, (clf_base, param_dist) in classifiers_and_params.items():\n",
        "        print(f\"\\nüîç {clf_name} on Fold {fold_number}\")\n",
        "\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=clf_base,\n",
        "            param_distributions=param_dist,\n",
        "            n_iter=10,\n",
        "            scoring=\"f1\",\n",
        "            cv=3,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        random_search.fit(X_train_fold, y_train_fold)\n",
        "        best_model = random_search.best_estimator_\n",
        "        print(\"Best params:\", random_search.best_params_)\n",
        "\n",
        "        y_train_pred = best_model.predict(X_train_fold)\n",
        "        y_test_pred = best_model.predict(X_test_fold)\n",
        "\n",
        "        y_train_prob = best_model.predict_proba(X_train_fold)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
        "        y_test_prob = best_model.predict_proba(X_test_fold)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
        "\n",
        "        # Evaluation\n",
        "        test_metrics = {\n",
        "            \"acc\": accuracy_score(y_test_fold, y_test_pred),\n",
        "            \"prec\": precision_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"rec\": recall_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"f1\": f1_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"auc\": roc_auc_score(y_test_fold, y_test_prob) if y_test_prob is not None else 0.0\n",
        "        }\n",
        "\n",
        "        print(f\"‚Üí Accuracy: {test_metrics['acc']:.3f} | F1: {test_metrics['f1']:.3f} | AUC: {test_metrics['auc']:.3f}\")\n",
        "\n",
        "        # Confusion Matrices\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        sns.heatmap(confusion_matrix(y_train_fold, y_train_pred), annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
        "        ax[0].set_title(f'{clf_name} - Fold {fold_number} - Train')\n",
        "\n",
        "        sns.heatmap(confusion_matrix(y_test_fold, y_test_pred), annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
        "        ax[1].set_title(f'{clf_name} - Fold {fold_number} - Test')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # ROC Curve\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        if y_train_prob is not None:\n",
        "            RocCurveDisplay.from_estimator(best_model, X_train_fold, y_train_fold, ax=ax[0])\n",
        "            ax[0].set_title(f\"{clf_name} - ROC (Train) - Fold {fold_number}\")\n",
        "        if y_test_prob is not None:\n",
        "            RocCurveDisplay.from_estimator(best_model, X_test_fold, y_test_fold, ax=ax[1])\n",
        "            ax[1].set_title(f\"{clf_name} - ROC (Test) - Fold {fold_number}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Save metrics\n",
        "        fold_metrics[\"Classifier\"].append(clf_name)\n",
        "        fold_metrics[\"Fold\"].append(fold_number)\n",
        "        fold_metrics[\"Accuracy\"].append(test_metrics[\"acc\"])\n",
        "        fold_metrics[\"Precision\"].append(test_metrics[\"prec\"])\n",
        "        fold_metrics[\"Recall\"].append(test_metrics[\"rec\"])\n",
        "        fold_metrics[\"F1 Score\"].append(test_metrics[\"f1\"])\n",
        "        fold_metrics[\"AUC ROC\"].append(test_metrics[\"auc\"])\n",
        "\n",
        "        # Detailed logs\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Train\", y_train_fold, y_train_pred, X_train_fold, y_train_fold, y_train_prob)\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Test\", y_test_fold, y_test_pred, X_test_fold, y_test_fold, y_test_prob)\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "# Summary\n",
        "print(\"\\nüìä Final Summary by Classifier (Average Across Folds):\")\n",
        "summary_df = pd.DataFrame(fold_metrics)\n",
        "grouped = summary_df.groupby(\"Classifier\")\n",
        "print(grouped.mean(numeric_only=True).round(3))\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv(\"churn_classifiers_output.csv\", index=False)\n",
        "print(\"\\n‚úÖ All results saved to churn_classifiers_output.csv\")\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3b2UiGXA_Z_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 4: Added 2 classifiers (boosters)\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Initialize results storage\n",
        "results_df = pd.DataFrame(columns=[\n",
        "    \"Classifier Name\", \"Fold\", \"TrainOrTest\",\n",
        "    \"Num Train Samples\", \"Num Churned in Train\",\n",
        "    \"TP\", \"TN\", \"FP\", \"FN\", \"ROC-AUC\"\n",
        "])\n",
        "\n",
        "fold_metrics = {\n",
        "    \"Classifier\": [], \"Fold\": [],\n",
        "    \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 Score\": [], \"AUC ROC\": []\n",
        "}\n",
        "\n",
        "# Logging function\n",
        "def log_metrics_to_df(df, classifier_name, fold_number, dataset_type, y_true, y_pred, X_data, y_data, y_prob):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "    roc_auc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
        "    row = {\n",
        "        \"Classifier Name\": classifier_name,\n",
        "        \"Fold\": fold_number,\n",
        "        \"TrainOrTest\": dataset_type,\n",
        "        \"Num Train Samples\": len(X_data),\n",
        "        \"Num Churned in Train\": sum(y_data == 1),\n",
        "        \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
        "        \"ROC-AUC\": roc_auc\n",
        "    }\n",
        "    return pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "\n",
        "   # Estimate class weight for scale_pos_weight\n",
        "neg, pos = (y == 0).sum(), (y == 1).sum()\n",
        "scale_pos_weight = neg / pos\n",
        "extra_classifiers = {\n",
        "\n",
        "    \"XGBoost\": (\n",
        "        XGBClassifier(\n",
        "            use_label_encoder=False,\n",
        "            eval_metric='logloss',\n",
        "            random_state=42,\n",
        "            n_jobs=-1,  # Parallelization\n",
        "            scale_pos_weight=scale_pos_weight  # Handles class imbalance\n",
        "        ),\n",
        "        {\n",
        "            \"n_estimators\": randint(100, 300),\n",
        "            \"max_depth\": randint(3, 10),\n",
        "            \"learning_rate\": uniform(0.01, 0.3),\n",
        "            \"subsample\": uniform(0.6, 0.4),\n",
        "            \"colsample_bytree\": uniform(0.6, 0.4),\n",
        "            \"reg_alpha\": uniform(0.1, 1.0),    # L1 regularization\n",
        "            \"reg_lambda\": uniform(1.0, 3.0)    # L2 regularization\n",
        "        }\n",
        "    ),\n",
        "    \"GradientBoosting\": (\n",
        "        GradientBoostingClassifier(\n",
        "            random_state=42\n",
        "        ),\n",
        "        {\n",
        "            \"n_estimators\": randint(100, 300),\n",
        "            \"max_depth\": randint(3, 10),\n",
        "            \"learning_rate\": uniform(0.01, 0.3),\n",
        "            \"subsample\": uniform(0.6, 0.4),\n",
        "            \"min_samples_split\": randint(2, 10),  # Regularization\n",
        "            \"min_samples_leaf\": randint(1, 10),   # Regularization\n",
        "            \"max_features\": [\"auto\", \"sqrt\", \"log2\"]  # Feature usage regularization\n",
        "        }\n",
        "    )\n",
        "}\n",
        "# Begin loop\n",
        "fold_number = 1\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    # Apply SMOTE only on training data\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_fold, y_train_fold = smote.fit_resample(X_train_fold, y_train_fold)\n",
        "\n",
        "\n",
        "    for clf_name, (clf_base, param_dist) in extra_classifiers.items():\n",
        "        print(f\"\\nüîç {clf_name} on Fold {fold_number}\")\n",
        "\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=clf_base,\n",
        "            param_distributions=param_dist,\n",
        "            n_iter=10,\n",
        "            scoring=\"f1\",\n",
        "            cv=3,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        random_search.fit(X_train_fold, y_train_fold)\n",
        "        best_model = random_search.best_estimator_\n",
        "        print(\"Best params:\", random_search.best_params_)\n",
        "\n",
        "        y_train_pred = best_model.predict(X_train_fold)\n",
        "        y_test_pred = best_model.predict(X_test_fold)\n",
        "\n",
        "        y_train_prob = best_model.predict_proba(X_train_fold)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
        "        y_test_prob = best_model.predict_proba(X_test_fold)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
        "\n",
        "        # Evaluation\n",
        "        test_metrics = {\n",
        "            \"acc\": accuracy_score(y_test_fold, y_test_pred),\n",
        "            \"prec\": precision_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"rec\": recall_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"f1\": f1_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"auc\": roc_auc_score(y_test_fold, y_test_prob) if y_test_prob is not None else 0.0\n",
        "        }\n",
        "\n",
        "        print(f\"‚Üí Accuracy: {test_metrics['acc']:.3f} | F1: {test_metrics['f1']:.3f} | AUC: {test_metrics['auc']:.3f}\")\n",
        "\n",
        "        # Confusion Matrices\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        sns.heatmap(confusion_matrix(y_train_fold, y_train_pred), annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
        "        ax[0].set_title(f'{clf_name} - Fold {fold_number} - Train')\n",
        "\n",
        "        sns.heatmap(confusion_matrix(y_test_fold, y_test_pred), annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
        "        ax[1].set_title(f'{clf_name} - Fold {fold_number} - Test')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # ROC Curve\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        if y_train_prob is not None:\n",
        "            RocCurveDisplay.from_estimator(best_model, X_train_fold, y_train_fold, ax=ax[0])\n",
        "            ax[0].set_title(f\"{clf_name} - ROC (Train) - Fold {fold_number}\")\n",
        "        if y_test_prob is not None:\n",
        "            RocCurveDisplay.from_estimator(best_model, X_test_fold, y_test_fold, ax=ax[1])\n",
        "            ax[1].set_title(f\"{clf_name} - ROC (Test) - Fold {fold_number}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Save metrics\n",
        "        fold_metrics[\"Classifier\"].append(clf_name)\n",
        "        fold_metrics[\"Fold\"].append(fold_number)\n",
        "        fold_metrics[\"Accuracy\"].append(test_metrics[\"acc\"])\n",
        "        fold_metrics[\"Precision\"].append(test_metrics[\"prec\"])\n",
        "        fold_metrics[\"Recall\"].append(test_metrics[\"rec\"])\n",
        "        fold_metrics[\"F1 Score\"].append(test_metrics[\"f1\"])\n",
        "        fold_metrics[\"AUC ROC\"].append(test_metrics[\"auc\"])\n",
        "\n",
        "        # Detailed logs\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Train\", y_train_fold, y_train_pred, X_train_fold, y_train_fold, y_train_prob)\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Test\", y_test_fold, y_test_pred, X_test_fold, y_test_fold, y_test_prob)\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "# Summary\n",
        "print(\"\\nüìä Final Summary by Classifier (Average Across Folds):\")\n",
        "summary_df = pd.DataFrame(fold_metrics)\n",
        "grouped = summary_df.groupby(\"Classifier\")\n",
        "print(grouped.mean(numeric_only=True).round(3))\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv(\"churn_classifiers_output.csv\", index=False)\n",
        "print(\"\\n‚úÖ All results saved to churn_classifiers_output.csv\")\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1OspvzD6Vzc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXP4 NN ‚Äì SMOTE Oversampling for Neural Network\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# For logging results\n",
        "nn_results = []\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# SMOTE setup\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "fold_number = 1\n",
        "for train_index, test_index in skf.split(X_scaled, y):\n",
        "    print(f\"\\nüß† Neural Network (SMOTE) - Fold {fold_number}\")\n",
        "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Apply SMOTE to training data only\n",
        "    X_train_fold, y_train_fold = smote.fit_resample(X_train_fold, y_train_fold)\n",
        "\n",
        "    print(f\"Resampled training distribution: {np.bincount(y_train_fold)}\")\n",
        "\n",
        "    # Model definition\n",
        "    model = Sequential([\n",
        "        Dense(256, activation='relu', input_shape=(X_train_fold.shape[1],)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0005),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "\n",
        "    # Training\n",
        "    history = model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        validation_split=0.2,\n",
        "        epochs=50,\n",
        "        batch_size=64,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    print(f\"Epochs trained: {len(history.history['loss'])}\")\n",
        "\n",
        "    # Predictions\n",
        "    y_test_prob = model.predict(X_test_fold).flatten()\n",
        "    y_test_pred = (y_test_prob > 0.5).astype(int)\n",
        "\n",
        "    # Evaluation\n",
        "    acc = accuracy_score(y_test_fold, y_test_pred)\n",
        "    prec = precision_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "    rec = recall_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test_fold, y_test_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_test_fold, y_test_prob)\n",
        "\n",
        "    print(f\"‚Üí Accuracy: {acc:.3f} | F1: {f1:.3f} | AUC: {auc:.3f}\")\n",
        "\n",
        "    # Log results\n",
        "    nn_results.append({\n",
        "        \"Classifier\": \"NeuralNetwork_SMOTE\",\n",
        "        \"Fold\": fold_number,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1 Score\": f1,\n",
        "        \"AUC ROC\": auc\n",
        "    })\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test_fold, y_test_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"NN (SMOTE) - Confusion Matrix - Fold {fold_number}\")\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    RocCurveDisplay.from_predictions(y_test_fold, y_test_prob)\n",
        "    plt.title(f\"NN (SMOTE) - ROC Curve - Fold {fold_number}\")\n",
        "    plt.show()\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "# Plot Accuracy and Loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Convert to DataFrame if needed\n",
        "nn_results_df = pd.DataFrame(nn_results)\n",
        "print(\"\\nüìä Neural Network (SMOTE) Evaluation (Average Across Folds):\")\n",
        "print(nn_results_df.groupby(\"Classifier\").mean(numeric_only=True).round(3))\n"
      ],
      "metadata": {
        "id": "f37BnP_XNq4k",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 5- Baseline (default) training on top 20 features\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, RocCurveDisplay\n",
        ")\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ----------------------------\n",
        "# 1Ô∏è‚É£ Use top 20 features\n",
        "# ----------------------------\n",
        "X_encoded = pd.get_dummies(X)  # Same encoding as when you ranked features\n",
        "X_top20 = X_encoded[top_20_features]  # ‚Üê Your top 20 list\n",
        "print(f\"Shape of X with top 20 features: {X_top20.shape}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 2Ô∏è‚É£ Initialize storage\n",
        "# ----------------------------\n",
        "results_df = pd.DataFrame(columns=[\n",
        "    \"Classifier Name\", \"Fold\", \"TrainOrTest\",\n",
        "    \"Num Train Samples\", \"Num Churned in Train\",\n",
        "    \"TP\", \"TN\", \"FP\", \"FN\", \"ROC-AUC\"\n",
        "])\n",
        "\n",
        "fold_metrics = {\n",
        "    \"Classifier\": [], \"Fold\": [],\n",
        "    \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 Score\": [], \"AUC ROC\": []\n",
        "}\n",
        "\n",
        "# ----------------------------\n",
        "# 3Ô∏è‚É£ Logging helper\n",
        "# ----------------------------\n",
        "def log_metrics_to_df(df, classifier_name, fold_number, dataset_type, y_true, y_pred, X_data, y_data, y_prob):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "    roc_auc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
        "    row = {\n",
        "        \"Classifier Name\": classifier_name,\n",
        "        \"Fold\": fold_number,\n",
        "        \"TrainOrTest\": dataset_type,\n",
        "        \"Num Train Samples\": len(X_data),\n",
        "        \"Num Churned in Train\": sum(y_data == 1),\n",
        "        \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
        "        \"ROC-AUC\": roc_auc\n",
        "    }\n",
        "    return pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "\n",
        "# ----------------------------\n",
        "# 4Ô∏è‚É£ ML classifiers + XGBoost + GBM\n",
        "# ----------------------------\n",
        "classifiers_and_params = {\n",
        "    \"kNN\": (\n",
        "        KNeighborsClassifier(),\n",
        "        {\n",
        "            \"n_neighbors\": randint(1, 50),\n",
        "            \"weights\": [\"uniform\", \"distance\"],\n",
        "            \"p\": [1, 2]\n",
        "        }\n",
        "    ),\n",
        "    \"LDA\": (\n",
        "        LinearDiscriminantAnalysis(),\n",
        "        [\n",
        "            {\"solver\": [\"svd\"], \"shrinkage\": [None], \"tol\": uniform(1e-5, 1e-2)},\n",
        "            {\"solver\": [\"lsqr\", \"eigen\"], \"shrinkage\": [None, \"auto\"], \"tol\": uniform(1e-5, 1e-2)}\n",
        "        ]\n",
        "    ),\n",
        "    \"LogReg\": (\n",
        "        LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced'),\n",
        "        {\n",
        "            \"C\": uniform(0.01, 10),\n",
        "            \"penalty\": [\"l1\", \"l2\"],\n",
        "            \"solver\": [\"liblinear\", \"saga\"]\n",
        "        }\n",
        "    ),\n",
        "    \"DecisionTree\": (\n",
        "        DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
        "        {\n",
        "            \"max_depth\": randint(1, 20),\n",
        "            \"min_samples_split\": randint(2, 10),\n",
        "            \"min_samples_leaf\": randint(1, 10),\n",
        "            \"criterion\": [\"gini\", \"entropy\"]\n",
        "        }\n",
        "    ),\n",
        "    \"RandomForest\": (\n",
        "        RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
        "        {\n",
        "            \"n_estimators\": randint(50, 300),\n",
        "            \"max_depth\": randint(1, 20),\n",
        "            \"min_samples_split\": randint(2, 10),\n",
        "            \"min_samples_leaf\": randint(1, 10),\n",
        "            \"criterion\": [\"gini\", \"entropy\"]\n",
        "        }\n",
        "    ),\n",
        "    \"NaiveBayes\": (\n",
        "        GaussianNB(),\n",
        "        {\n",
        "            \"var_smoothing\": uniform(1e-9, 1e-5)\n",
        "        }\n",
        "    ),\n",
        "    \"AdaBoost\": (\n",
        "        AdaBoostClassifier(random_state=42),\n",
        "        {\n",
        "            \"n_estimators\": randint(50, 300),\n",
        "            \"learning_rate\": uniform(0.01, 0.5)\n",
        "        }\n",
        "    ),\n",
        "    \"XGBoost\": (\n",
        "        XGBClassifier(random_state=42, n_jobs=-1, use_label_encoder=False, eval_metric='logloss'),\n",
        "        {\n",
        "            \"n_estimators\": randint(50, 300),\n",
        "            \"max_depth\": randint(2, 10),\n",
        "            \"learning_rate\": uniform(0.01, 0.3),\n",
        "            \"subsample\": uniform(0.7, 0.3),\n",
        "            \"colsample_bytree\": uniform(0.7, 0.3),\n",
        "            \"reg_alpha\": uniform(0, 1),\n",
        "            \"reg_lambda\": uniform(0, 1)\n",
        "        }\n",
        "    ),\n",
        "    \"GBM\": (\n",
        "        GradientBoostingClassifier(random_state=42),\n",
        "        {\n",
        "            \"n_estimators\": randint(50, 300),\n",
        "            \"learning_rate\": uniform(0.01, 0.3),\n",
        "            \"max_depth\": randint(2, 10),\n",
        "            \"subsample\": uniform(0.7, 0.3)\n",
        "        }\n",
        "    )\n",
        "}\n",
        "\n",
        "# ----------------------------\n",
        "# 5Ô∏è‚É£ CV loop for ML models\n",
        "# ----------------------------\n",
        "fold_number = 1\n",
        "for train_index, test_index in skf.split(X_top20, y):\n",
        "    X_train_fold = X_top20.iloc[train_index]\n",
        "    X_test_fold = X_top20.iloc[test_index]\n",
        "    y_train_fold = y.iloc[train_index]\n",
        "    y_test_fold = y.iloc[test_index]\n",
        "\n",
        "    for clf_name, (clf_base, param_dist) in classifiers_and_params.items():\n",
        "        print(f\"\\nüîç {clf_name} on Fold {fold_number}\")\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=clf_base,\n",
        "            param_distributions=param_dist,\n",
        "            n_iter=10,\n",
        "            scoring=\"f1\",\n",
        "            cv=3,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        random_search.fit(X_train_fold, y_train_fold)\n",
        "        best_model = random_search.best_estimator_\n",
        "        print(\"Best params:\", random_search.best_params_)\n",
        "\n",
        "        y_train_pred = best_model.predict(X_train_fold)\n",
        "        y_test_pred = best_model.predict(X_test_fold)\n",
        "        y_train_prob = best_model.predict_proba(X_train_fold)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
        "        y_test_prob = best_model.predict_proba(X_test_fold)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
        "\n",
        "        test_metrics = {\n",
        "            \"acc\": accuracy_score(y_test_fold, y_test_pred),\n",
        "            \"prec\": precision_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"rec\": recall_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"f1\": f1_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "            \"auc\": roc_auc_score(y_test_fold, y_test_prob) if y_test_prob is not None else 0.0\n",
        "        }\n",
        "        print(f\"‚Üí Accuracy: {test_metrics['acc']:.3f} | F1: {test_metrics['f1']:.3f} | AUC: {test_metrics['auc']:.3f}\")\n",
        "\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        sns.heatmap(confusion_matrix(y_train_fold, y_train_pred), annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
        "        sns.heatmap(confusion_matrix(y_test_fold, y_test_pred), annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        if y_train_prob is not None:\n",
        "            RocCurveDisplay.from_estimator(best_model, X_train_fold, y_train_fold, ax=ax[0])\n",
        "        if y_test_prob is not None:\n",
        "            RocCurveDisplay.from_estimator(best_model, X_test_fold, y_test_fold, ax=ax[1])\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        fold_metrics[\"Classifier\"].append(clf_name)\n",
        "        fold_metrics[\"Fold\"].append(fold_number)\n",
        "        fold_metrics[\"Accuracy\"].append(test_metrics[\"acc\"])\n",
        "        fold_metrics[\"Precision\"].append(test_metrics[\"prec\"])\n",
        "        fold_metrics[\"Recall\"].append(test_metrics[\"rec\"])\n",
        "        fold_metrics[\"F1 Score\"].append(test_metrics[\"f1\"])\n",
        "        fold_metrics[\"AUC ROC\"].append(test_metrics[\"auc\"])\n",
        "\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Train\", y_train_fold, y_train_pred, X_train_fold, y_train_fold, y_train_prob)\n",
        "        results_df = log_metrics_to_df(results_df, clf_name, fold_number, \"Test\", y_test_fold, y_test_pred, X_test_fold, y_test_fold, y_test_prob)\n",
        "\n",
        "    # ‚úÖ Add NN exactly like your original\n",
        "    print(f\"\\nüß† Neural Network on Fold {fold_number}\")\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_fold)\n",
        "    X_test_scaled = scaler.transform(X_test_fold)\n",
        "\n",
        "    model = Sequential([\n",
        "        Dense(256, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0005),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "    history = model.fit(\n",
        "        X_train_scaled, y_train_fold,\n",
        "        validation_split=0.2,\n",
        "        epochs=50,\n",
        "        batch_size=64,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "    print(f\"Epochs trained: {len(history.history['loss'])}\")\n",
        "\n",
        "    y_train_prob = model.predict(X_train_scaled).flatten()\n",
        "    y_test_prob = model.predict(X_test_scaled).flatten()\n",
        "    y_train_pred = (y_train_prob > 0.5).astype(int)\n",
        "    y_test_pred = (y_test_prob > 0.5).astype(int)\n",
        "\n",
        "    test_metrics = {\n",
        "        \"acc\": accuracy_score(y_test_fold, y_test_pred),\n",
        "        \"prec\": precision_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "        \"rec\": recall_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "        \"f1\": f1_score(y_test_fold, y_test_pred, zero_division=0),\n",
        "        \"auc\": roc_auc_score(y_test_fold, y_test_prob)\n",
        "    }\n",
        "    print(f\"‚Üí NN Accuracy: {test_metrics['acc']:.3f} | F1: {test_metrics['f1']:.3f} | AUC: {test_metrics['auc']:.3f}\")\n",
        "\n",
        "    results_df = log_metrics_to_df(results_df, \"DNN\", fold_number, \"Train\", y_train_fold, y_train_pred, X_train_scaled, y_train_fold, y_train_prob)\n",
        "    results_df = log_metrics_to_df(results_df, \"DNN\", fold_number, \"Test\", y_test_fold, y_test_pred, X_test_scaled, y_test_fold, y_test_prob)\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "print(\"\\nüìä Final Summary:\")\n",
        "summary_df = pd.DataFrame(fold_metrics)\n",
        "print(summary_df.groupby(\"Classifier\").mean(numeric_only=True).round(3))\n",
        "\n",
        "results_df.to_csv(\"churn_exp5_top20.csv\", index=False)\n",
        "print(\"‚úÖ All results saved to churn_exp5_top20.csv\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "I1wCRhF3qQPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚öôÔ∏è Encode your final X exactly as you‚Äôll use it\n",
        "X_encoded = pd.get_dummies(X)\n",
        "\n",
        "# ‚úÖ Use the encoded version to refit RF and get new top 20\n",
        "rf_for_selection = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_for_selection.fit(X_encoded, y)\n",
        "importances = pd.Series(rf_for_selection.feature_importances_, index=X_encoded.columns)\n",
        "important_features = importances.sort_values(ascending=False)\n",
        "top_20_features = important_features.head(20).index.tolist()\n",
        "\n",
        "# Subset\n",
        "X_top20 = X_encoded[top_20_features]\n",
        "print(\"Top 20 features:\", top_20_features)\n"
      ],
      "metadata": {
        "id": "S7RS4odErshu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvgiIiYUCNC+sSQUHifGE7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}